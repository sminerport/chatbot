{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intents_train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1wCci9CoVykMZnk1n1GzNTZjoWMx3Ijv4","authorship_tag":"ABX9TyOpCTK/DJqEwkEPgHs8XJlS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"0mBFhHY_tSdq","executionInfo":{"status":"ok","timestamp":1633762655908,"user_tz":360,"elapsed":126,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["#save default font settings\n","IPython_default = plt.rcParams.copy()\n","\n","# set fonts / set text size\n","#@title matplotlib font settings\n","small_text = 15 #@param {type:\"integer\"}\n","medium_text = 26 #@param {type:\"integer\"}\n","large_text = 28 #@param {type:\"integer\"}\n","line_marker_size = 7 #@param {type:\"slider\", min:0, max:10, step:0.5}\n","legend_shadow = True #@param {type:\"boolean\"}\n","fig_width =  8 #@param {type:\"number\"}\n","fig_height =  6 #@param {type:\"number\"}\n","sns_style = \"ticks\" #@param [\"darkgrid\", \"whitegrid\", \"dark\", \"white\", \"ticks\"]\n","axis_grid = True #@param {type:\"boolean\"}\n","sns_palette = \"deep\" #@param [\"pastel\", \"muted\", \"bright\", \"deep\", \"colorblind\", \"dark\"]\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# restore defaults\n","plt.rcdefaults()\n","\n","#run configuration parameters\n","plt.rcParams['axes.labelsize']   = small_text\n","plt.rcParams['axes.titlesize']   = small_text\n","plt.rcParams['xtick.labelsize']  = small_text\n","plt.rcParams['ytick.labelsize']  = small_text\n","plt.rcParams['legend.fontsize']  = small_text\n","plt.rcParams['legend.shadow']    = legend_shadow\n","plt.rcParams['lines.markersize'] = line_marker_size\n","plt.rcParams['figure.figsize']   = (fig_width, fig_height)\n","plt.rcParams['font.size']        = small_text\n","\n","# seaborn settings\n","sns.set_style(sns_style, {\"axes.grid\": axis_grid})\n","sns.set_palette(sns_palette)\n"],"execution_count":298,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wFE1Byn9bRGk"},"source":["# Download Embeddings"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhdglgD9YENs","executionInfo":{"status":"ok","timestamp":1633765993519,"user_tz":360,"elapsed":164,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"6538ef1f-16cc-4520-9695-a6e8af15902d"},"source":["import os\n","import tqdm\n","import requests\n","import zipfile\n","\n","URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n","\n","def fetch_data(url=URL,target_file='/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.zip', delete_zip=False):\n","    # if dataset exists exit\n","    if os.path.isfile(target_file):\n","        print('datasets already downloaded')\n","        return\n","\n","        #download (large) zip file\n","    #for large https request on stream mode to avoid out of memory issues\n","    #see : http://masnun.com/2016/09/18/python-using-the-requests-module-to-download-large-files-efficiently.html\n","    print(\"**************************\")\n","    print(\"  Downloading zip file\")\n","    print(\"  >_<  Please wait >_< \")\n","    print(\"**************************\")\n","    response = requests.get(url, stream=True)\n","    #read chunk by chunk\n","    handle = open(target_file, \"wb\")\n","    for chunk in tqdm.tqdm(response.iter_content(chunk_size=512)):\n","        if chunk:  \n","            handle.write(chunk)\n","    handle.close()  \n","    print(\"  Download completed ;) :\") \n","    #extract zip_file\n","    zf = zipfile.ZipFile(target_file)\n","    print(\"1. Extracting {} file\".format(target_file))\n","    zf.extractall(path='/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings')\n","    if delete_zip:\n","        print(\"2. Deleting {} file\".format(dataset_name+\".zip\"))\n","        os.remove(path=zip_file)\n","\n","fetch_data()"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["datasets already downloaded\n"]}]},{"cell_type":"markdown","metadata":{"id":"olOEGjoHK_oM"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"BhS9gqsQQcHk","executionInfo":{"status":"ok","timestamp":1633767199354,"user_tz":360,"elapsed":144,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"50296a71-9858-4363-b8cb-703a0dfa5062"},"source":["import os\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import json\n","import pickle\n","\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers import SGD\n","import random\n","from sklearn import preprocessing\n"],"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"CD7iDv_WLEm4"},"source":["# Set Variables"]},{"cell_type":"code","metadata":{"id":"IEoYFgQlK66T","executionInfo":{"status":"ok","timestamp":1633767203939,"user_tz":360,"elapsed":149,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["MODEL_NAME1 = 'best_model_scratch.h5'\n","MODEL_NAME2 = 'best_model_pretrained.h5'\n","model_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models'\n","\n","model_path_scratch = os.path.join(model_path, MODEL_NAME1)\n","model_path_pretrained = os.path.join(model_path, MODEL_NAME2)\n","\n","intents_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/data/intents'\n","\n","# inference model variables\n","inference_load_intents_from = os.path.join(intents_path, 'intents_job_intents.json')\n","\n","words = []\n","tags = []\n","classes = []\n","documents = []\n","all_patterns = []\n","all_tags = []\n","label_encoded_Y = []\n","x_tr_seq = []\n","x_val_seq = []\n","y_tr = []\n","y_val = []\n","ignore_words = ['?', '!']"],"execution_count":100,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFxx-KBDCPWc"},"source":["# Load JSON"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"9JDcFJogdKsd","executionInfo":{"status":"ok","timestamp":1633767220956,"user_tz":360,"elapsed":152,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["data_file = open(inference_load_intents_from, encoding='cp1252').read()\n","intents = json.loads(data_file)"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"id":"QINbMiEJ5Px_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yOioSpstC1P7"},"source":["## Read in patterns and tags\n","\n","Patterns are the user input (i.e., 'Hi,' 'How are you?').\n","\n","Nothing is tokenized here."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8Yd42VXCtgO","executionInfo":{"status":"ok","timestamp":1633767224560,"user_tz":360,"elapsed":148,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"b64272eb-23a0-4b9a-ac54-371bd36bcd9a"},"source":["# print classes\n","for intent in intents['intents']:\n","    all_patterns.extend(intent['patterns'])\n","    for pattern in intent['patterns']:\n","        all_tags.append(intent['tag'])\n","        w = nltk.word_tokenize(pattern)\n","        words.extend(w)\n","        documents.append((w, intent['tag']))\n","\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])\n","\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n","classes = sorted(list(set(classes)))\n","\n","print(len(documents), 'documents')\n","print(len(classes), 'classes', classes)\n","print(len(words), 'unique lemmatized words', words)\n","\n","print(all_tags)\n","print(all_patterns)"],"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["61 documents\n","11 classes ['compliment', 'feeling', 'goodbye', 'greeting', 'manager', 'name', 'package_tracking', 'profane', 'return_product', 'thanks', 'tracking']\n","88 unique lemmatized words [\"'\", \"'s\", ',', '.', '0983834298342341', '1234509873234323', '1983-2343-2343-2343', 'a', 'am', 'are', 'back', 'broken', 'bye', 'can', 'computer', 'dead', 'device', 'die', 'do', 'doing', 'drop', 'equipment', 'feel', 'feeling', 'fix', 'fixed', 'get', 'give', 'go', 'going', 'good', 'goodbye', 'hate', 'have', 'hear', 'hello', 'help', 'helpful', 'here', 'hi', 'how', 'i', 'is', 'it', 'later', 'like', 'long', 'manager', 'me', 'money', 'my', 'name', 'need', 'not', 'now', 'package', 'product', 'refund', 'report', 'return', 'see', 'shipment', 'some', 'something', 'speak', 'speaking', 'supervisor', 'take', 'talk', 'thank', 'thanks', 'that', 'the', 'there', 'to', 'today', 'track', 'unhappy', 'very', 'want', 'what', 'where', 'who', 'whom', 'will', 'with', 'you', 'your']\n","['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'feeling', 'feeling', 'feeling', 'feeling', 'feeling', 'feeling', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'compliment', 'thanks', 'thanks', 'name', 'name', 'name', 'name', 'manager', 'manager', 'manager', 'manager', 'manager', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'profane', 'profane', 'profane', 'tracking', 'tracking', 'tracking']\n","['Hello', 'Hi', 'Good to see you.', 'Hello, there!', 'Can you hear me?', 'Where are you?', 'How are you today?', 'How are you doing today?', \"How's it going?'\", 'How are you feeling?', 'How do you feel?', 'How is it going?', 'I have to go.', 'Bye', 'Goodbye', 'See you later', 'Talk to you later', 'You are very helpful', 'Thanks', 'Thank you', 'What is your name?', 'Name?', 'Who are you?', 'With whom am I speaking?', 'Can I speak to your manager?', 'Give me the manager!', 'I want your supervisor.', 'I am going to report you.', 'Get me to your supervisor.', 'I am unhappy with your product.', 'I need to return a product.', 'I need a refund!', 'I need to get some help.', 'I want my money back.', 'My computer is broken.', 'My equipment is broken.', 'My computer needs fixed.', 'I need you to fix something', 'I do not like your product', 'I want my money back.', 'I want a refund, now!', 'Give me my money back!', 'I hate your product.', 'My device is broken.', 'I need you to fix my computer', 'I want a refund', 'I need to return a package.', 'I want to return a product.', 'I have a product that I want to return.', 'How can I track my package?', 'Where is my package?', 'How long will my package take to get here?', 'I want to track my package.', 'Can you help me track my package?', 'I want to track my shipment.', 'Drop dead.', 'I hate you.', 'I want you to die.', '1983-2343-2343-2343', '1234509873234323', '0983834298342341']\n"]}]},{"cell_type":"markdown","metadata":{"id":"a1RyLAppDkf7"},"source":["## Encode Tags\n"]},{"cell_type":"markdown","metadata":{"id":"XMGIsSR_D-Dm"},"source":["\n","### Fit"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ey2tdhgWDCyq","executionInfo":{"status":"ok","timestamp":1633767227588,"user_tz":360,"elapsed":181,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"29915378-008e-4af0-948e-ced9c9bfe2bd"},"source":["# create label encoder\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","# fit on all tags from JSON file\n","le.fit(all_tags)\n","print(f'Number of classes: {len(list(le.classes_))}')"],"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes: 11\n"]}]},{"cell_type":"markdown","metadata":{"id":"A38hiFKfEoh7"},"source":["### Transform"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nktR6B85FKbT","executionInfo":{"status":"ok","timestamp":1633767230434,"user_tz":360,"elapsed":238,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"35f1ebf3-11ec-46af-deb1-ca50a259a8a1"},"source":["label_encoded_Y = le.transform(all_tags)\n","print(f'Label_encoded_Y: {label_encoded_Y}')\n","print(f'Label_encoded_Y bincount: {np.bincount(label_encoded_Y)}')"],"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["Label_encoded_Y: [ 3  3  3  3  3  3  1  1  1  1  1  1  2  2  2  2  2  0  9  9  5  5  5  5\n","  4  4  4  4  4  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n","  8  6  6  6  6  6  6  7  7  7 10 10 10]\n","Label_encoded_Y bincount: [ 1  6  5  6  5  4  6  3 20  2  3]\n"]}]},{"cell_type":"markdown","metadata":{"id":"bwhM8NHIGtFu"},"source":["## Create x_all, y_all"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48px4VM8DsZD","executionInfo":{"status":"ok","timestamp":1633767232834,"user_tz":360,"elapsed":171,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"83440261-9e03-4d8d-a67e-6bd3081325ef"},"source":["X_all = np.asarray(all_patterns)\n","y_all = np.asarray(label_encoded_Y)\n","print(f'X all shape: {X_all.shape}')\n","print(f'Y all shape: {y_all.shape}')\n","print(f'y_all: {y_all}')"],"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["X all shape: (61,)\n","Y all shape: (61,)\n","y_all: [ 3  3  3  3  3  3  1  1  1  1  1  1  2  2  2  2  2  0  9  9  5  5  5  5\n","  4  4  4  4  4  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n","  8  6  6  6  6  6  6  7  7  7 10 10 10]\n"]}]},{"cell_type":"markdown","metadata":{"id":"YWzLTI7BJEiK"},"source":["# Tokenize"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4leW3FIJHnj","executionInfo":{"status":"ok","timestamp":1633767235549,"user_tz":360,"elapsed":142,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"db45a022-b434-458b-b4c0-da678659d515"},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(list(X_all))\n","print(tokenizer.word_index)\n","with open('/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/data/intents/tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","X_all_seq = tokenizer.texts_to_sequences(X_all)\n","print(X_all_seq)"],"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["{'i': 1, 'you': 2, 'to': 3, 'my': 4, 'want': 5, 'how': 6, 'your': 7, 'a': 8, 'are': 9, 'is': 10, 'product': 11, 'need': 12, 'package': 13, 'me': 14, 'can': 15, 'return': 16, 'track': 17, 'going': 18, 'am': 19, 'get': 20, 'refund': 21, 'money': 22, 'back': 23, 'computer': 24, 'broken': 25, '2343': 26, 'hello': 27, 'see': 28, 'where': 29, 'today': 30, 'it': 31, 'do': 32, 'have': 33, 'later': 34, 'name': 35, 'with': 36, 'manager': 37, 'give': 38, 'supervisor': 39, 'help': 40, 'fix': 41, 'hate': 42, 'hi': 43, 'good': 44, 'there': 45, 'hear': 46, 'doing': 47, \"how's\": 48, \"'\": 49, 'feeling': 50, 'feel': 51, 'go': 52, 'bye': 53, 'goodbye': 54, 'talk': 55, 'very': 56, 'helpful': 57, 'thanks': 58, 'thank': 59, 'what': 60, 'who': 61, 'whom': 62, 'speaking': 63, 'speak': 64, 'the': 65, 'report': 66, 'unhappy': 67, 'some': 68, 'equipment': 69, 'needs': 70, 'fixed': 71, 'something': 72, 'not': 73, 'like': 74, 'now': 75, 'device': 76, 'that': 77, 'long': 78, 'will': 79, 'take': 80, 'here': 81, 'shipment': 82, 'drop': 83, 'dead': 84, 'die': 85, '1983': 86, '1234509873234323': 87, '0983834298342341': 88}\n","[[27], [43], [44, 3, 28, 2], [27, 45], [15, 2, 46, 14], [29, 9, 2], [6, 9, 2, 30], [6, 9, 2, 47, 30], [48, 31, 18, 49], [6, 9, 2, 50], [6, 32, 2, 51], [6, 10, 31, 18], [1, 33, 3, 52], [53], [54], [28, 2, 34], [55, 3, 2, 34], [2, 9, 56, 57], [58], [59, 2], [60, 10, 7, 35], [35], [61, 9, 2], [36, 62, 19, 1, 63], [15, 1, 64, 3, 7, 37], [38, 14, 65, 37], [1, 5, 7, 39], [1, 19, 18, 3, 66, 2], [20, 14, 3, 7, 39], [1, 19, 67, 36, 7, 11], [1, 12, 3, 16, 8, 11], [1, 12, 8, 21], [1, 12, 3, 20, 68, 40], [1, 5, 4, 22, 23], [4, 24, 10, 25], [4, 69, 10, 25], [4, 24, 70, 71], [1, 12, 2, 3, 41, 72], [1, 32, 73, 74, 7, 11], [1, 5, 4, 22, 23], [1, 5, 8, 21, 75], [38, 14, 4, 22, 23], [1, 42, 7, 11], [4, 76, 10, 25], [1, 12, 2, 3, 41, 4, 24], [1, 5, 8, 21], [1, 12, 3, 16, 8, 13], [1, 5, 3, 16, 8, 11], [1, 33, 8, 11, 77, 1, 5, 3, 16], [6, 15, 1, 17, 4, 13], [29, 10, 4, 13], [6, 78, 79, 4, 13, 80, 3, 20, 81], [1, 5, 3, 17, 4, 13], [15, 2, 40, 14, 17, 4, 13], [1, 5, 3, 17, 4, 82], [83, 84], [1, 42, 2], [1, 5, 2, 3, 85], [86, 26, 26, 26], [87], [88]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"uVmE5G9RJyCp"},"source":["### Pad"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1tA5wqBJ0HS","executionInfo":{"status":"ok","timestamp":1633767238395,"user_tz":360,"elapsed":185,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"039f6d11-a3e2-47e6-f5fa-94735c7d7f92"},"source":["# padding to prepare sequences of same length\n","X_all_seq = pad_sequences(X_all_seq, maxlen=25)\n","print(X_all_seq)\n","#type is now a numpy.ndarray\n","print(type(X_all_seq))\n","print(f'Shape (X_all): {X_all_seq.shape}')"],"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0 ...  0  0 27]\n"," [ 0  0  0 ...  0  0 43]\n"," [ 0  0  0 ...  3 28  2]\n"," ...\n"," [ 0  0  0 ... 26 26 26]\n"," [ 0  0  0 ...  0  0 87]\n"," [ 0  0  0 ...  0  0 88]]\n","<class 'numpy.ndarray'>\n","Shape (X_all): (61, 25)\n"]}]},{"cell_type":"markdown","metadata":{"id":"J8ateuv7KQ7T"},"source":["# Vocab Size"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrgIj7a4KQ7T","executionInfo":{"status":"ok","timestamp":1633767241401,"user_tz":360,"elapsed":184,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"612c182a-e5af-4a18-e218-9a930fce2767"},"source":["size_of_vocabulary = len(tokenizer.word_index) + 1 #+1 for padding\n","print(tokenizer.word_index)\n","print(f'Size of vocab: {size_of_vocabulary}')"],"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["{'i': 1, 'you': 2, 'to': 3, 'my': 4, 'want': 5, 'how': 6, 'your': 7, 'a': 8, 'are': 9, 'is': 10, 'product': 11, 'need': 12, 'package': 13, 'me': 14, 'can': 15, 'return': 16, 'track': 17, 'going': 18, 'am': 19, 'get': 20, 'refund': 21, 'money': 22, 'back': 23, 'computer': 24, 'broken': 25, '2343': 26, 'hello': 27, 'see': 28, 'where': 29, 'today': 30, 'it': 31, 'do': 32, 'have': 33, 'later': 34, 'name': 35, 'with': 36, 'manager': 37, 'give': 38, 'supervisor': 39, 'help': 40, 'fix': 41, 'hate': 42, 'hi': 43, 'good': 44, 'there': 45, 'hear': 46, 'doing': 47, \"how's\": 48, \"'\": 49, 'feeling': 50, 'feel': 51, 'go': 52, 'bye': 53, 'goodbye': 54, 'talk': 55, 'very': 56, 'helpful': 57, 'thanks': 58, 'thank': 59, 'what': 60, 'who': 61, 'whom': 62, 'speaking': 63, 'speak': 64, 'the': 65, 'report': 66, 'unhappy': 67, 'some': 68, 'equipment': 69, 'needs': 70, 'fixed': 71, 'something': 72, 'not': 73, 'like': 74, 'now': 75, 'device': 76, 'that': 77, 'long': 78, 'will': 79, 'take': 80, 'here': 81, 'shipment': 82, 'drop': 83, 'dead': 84, 'die': 85, '1983': 86, '1234509873234323': 87, '0983834298342341': 88}\n","Size of vocab: 89\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMXUvTz8PqN1","executionInfo":{"status":"ok","timestamp":1633767243817,"user_tz":360,"elapsed":144,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"c92cea69-b511-4f28-9382-6b5126e5f092"},"source":["for doc in documents[:10]:\n","    print(doc[1])\n","    "],"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["greeting\n","greeting\n","greeting\n","greeting\n","greeting\n","greeting\n","feeling\n","feeling\n","feeling\n","feeling\n"]}]},{"cell_type":"markdown","metadata":{"id":"PsQveR24bXX4"},"source":["# Load the Whole Embedding into Memory"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iH6l0PNmY_oN","executionInfo":{"status":"ok","timestamp":1633766139024,"user_tz":360,"elapsed":106280,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"1e68e2d0-ffda-4096-bfbd-2cbf6c03ed4e"},"source":["# load the whole embedding into memory\n","path_to_glove_file = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.840B.300d.txt'\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Found 2195884 word vectors.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3eGsdvFZUrl","executionInfo":{"status":"ok","timestamp":1633767248600,"user_tz":360,"elapsed":161,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"d52560a0-86bb-4ddc-d5f5-90e1e2ad936f"},"source":["# create a weight matrix for words in training docs\n","# create a weight matrix for words in training docs\n","embedding_matrix = np.zeros((size_of_vocabulary, 300))\n","hits = 0\n","misses = 0\n","missedWords = []\n","for word, i in tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None and embedding_vector.shape[0] != 0:       \n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","        missedWords.append(word)\n","print(f'Converted {hits} words ({misses} misses)')\n","print(missedWords)       \n"],"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted 83 words (5 misses)\n","['to', 'is', \"how's\", '1234509873234323', '0983834298342341']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TeDOmSyOM5tl","collapsed":true,"executionInfo":{"status":"ok","timestamp":1633767254172,"user_tz":360,"elapsed":203,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"dc8e291f-5ccb-42c3-9393-8497e0422304"},"source":["pickle.dump(words,open(os.path.join(intents_path, 'intents_words.pkl'),'wb'))\n","pickle.dump(classes,open(os.path.join(intents_path, 'intents_classes.pkl'),'wb'))\n","training = []\n","output_empty = [0] * len(classes)\n","for seq, doc in zip(X_all_seq, documents):\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","    training.append([seq, output_row])\n","\n","print(training)"],"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["[[array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 27], dtype=int32), [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 43], dtype=int32), [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 44,  3, 28,  2], dtype=int32), [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0, 27, 45], dtype=int32), [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 15,  2, 46, 14], dtype=int32), [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0, 29,  9,  2], dtype=int32), [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6,  9,  2, 30], dtype=int32), [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  6,  9,  2, 47, 30], dtype=int32), [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 48, 31, 18, 49], dtype=int32), [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6,  9,  2, 50], dtype=int32), [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6, 32,  2, 51], dtype=int32), [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6, 10, 31, 18], dtype=int32), [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1, 33,  3, 52], dtype=int32), [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 53], dtype=int32), [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 54], dtype=int32), [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0, 28,  2, 34], dtype=int32), [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 55,  3,  2, 34], dtype=int32), [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  2,  9, 56, 57], dtype=int32), [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 58], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0, 59,  2], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 60, 10,  7, 35], dtype=int32), [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 35], dtype=int32), [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0, 61,  9,  2], dtype=int32), [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, 36, 62, 19,  1, 63], dtype=int32), [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0, 15,  1, 64,  3,  7, 37], dtype=int32), [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 38, 14, 65, 37], dtype=int32), [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1,  5,  7, 39], dtype=int32), [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 19, 18,  3, 66,  2], dtype=int32), [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, 20, 14,  3,  7, 39], dtype=int32), [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 19, 67, 36,  7, 11], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 12,  3, 16,  8, 11], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1, 12,  8, 21], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 12,  3, 20, 68, 40], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  1,  5,  4, 22, 23], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  4, 24, 10, 25], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  4, 69, 10, 25], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  4, 24, 70, 71], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 12,  2,  3, 41, 72], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 32, 73, 74,  7, 11], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  1,  5,  4, 22, 23], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  1,  5,  8, 21, 75], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, 38, 14,  4, 22, 23], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1, 42,  7, 11], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  4, 76, 10, 25], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  1, 12,  2,  3, 41,  4, 24], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1,  5,  8, 21], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 12,  3, 16,  8, 13], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1,  5,  3, 16,  8, 11], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n","       33,  8, 11, 77,  1,  5,  3, 16], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  6, 15,  1, 17,  4, 13], dtype=int32), [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 29, 10,  4, 13], dtype=int32), [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,\n","       78, 79,  4, 13, 80,  3, 20, 81], dtype=int32), [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1,  5,  3, 17,  4, 13], dtype=int32), [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0, 15,  2, 40, 14, 17,  4, 13], dtype=int32), [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1,  5,  3, 17,  4, 82], dtype=int32), [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0, 83, 84], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  1, 42,  2], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  1,  5,  2,  3, 85], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 86, 26, 26, 26], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 87], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], [array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 88], dtype=int32), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-zhidZVQ2Ki","executionInfo":{"status":"ok","timestamp":1633767264672,"user_tz":360,"elapsed":144,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"6b1d7431-a4e5-466f-f02c-3062e028514e"},"source":["random.shuffle(training)\n","training = np.array(training)\n","X_train_all = list(training[:,0])\n","y_train_all = list(training[:,1])\n","print(len(X_train_all))\n","print(len(y_train_all))"],"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["61\n","61\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n"]}]},{"cell_type":"markdown","metadata":{"id":"wHf5PTZAKl-x"},"source":["# Build Model"]},{"cell_type":"markdown","metadata":{"id":"y1H3hwe0PbVS"},"source":["## Create model bag of words\n","\n"]},{"cell_type":"code","metadata":{"id":"2LZxAuTdSugR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633767269974,"user_tz":360,"elapsed":178,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"e2a7b7ce-4f73-4208-ce6d-075be41a4846"},"source":["# init training data\n","training_bow = []\n","output_empty = [0] * len(classes)\n","for doc in documents:\n","    bag = []\n","    pattern_words = doc[0]\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training_bow.append([bag, output_row])\n","\n","random.shuffle(training_bow)\n","training_bow = np.array(training_bow)\n","# create train and test lists.  X - patterns, y - intents\n","X_train_bag = list(training_bow[:,0])\n","y_train_bag = list(training_bow[:,1])\n","print('Training data created')\n","print(f'X train: {X_train_bag}')\n","print(f'y train: {y_train_bag}')\n"],"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data created\n","X train: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","y train: [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"]}]},{"cell_type":"code","metadata":{"id":"PUzbRAeooQ5L","executionInfo":{"status":"ok","timestamp":1633767273669,"user_tz":360,"elapsed":127,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["\n","def create_model_bag():\n","\n","    model = Sequential()\n","    model.add(Dense(128, input_shape=(len(X_train_bag[0]),), activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(len(y_train_bag[0]), activation='softmax'))\n","\n","    # Compile model.  Stochastic gradient descent with Nesterov accelerated\n","    # gradient gives good\n","    # results for this model\n","    sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    print(model.summary())\n","\n","    return model"],"execution_count":114,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"quw2gWfXPVcp"},"source":["# Create model scratch"]},{"cell_type":"code","metadata":{"id":"EwHASd8wL7B1","executionInfo":{"status":"ok","timestamp":1633768132158,"user_tz":360,"elapsed":147,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","import numpy\n","from keras.callbacks import *\n","from keras.initializers import Constant\n","\n","def create_model_scratch():\n","    model = Sequential()\n","    #embedding layer\n","    model.add(Embedding(size_of_vocabulary,300,\n","                        input_length=25,\n","                        trainable=True))\n","    #lstm layer\n","    model.add(LSTM(128,return_sequences=True,dropout=0.2))\n","\n","    #Global Maxpooling\n","    model.add(GlobalMaxPooling1D())\n","\n","    #Dense Layer\n","    model.add(Dense(64,activation='relu'))\n","    model.add(Dense(len(y_train_all[0]),activation='softmax'))\n","\n","    #Add loss function, metrics, optimizer\n","    # Compile model.  Stochastic gradient descent with Nesterov accelerated\n","    # gradient gives good\n","    # results for this model\n","    sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","    #addingcallbacks\n","    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1000)\n","    #mc = ModelCheckpoint(model_path_scratch, monitor='val_accuracy', mode='max', \n","                         #save_best_only=True, verbose=1)\n","    \n","    print(model.summary())\n","\n","    return model\n","\n","    \n"],"execution_count":142,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"29LFKLwlLxNC"},"source":["## Create pretrained model"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"UUMhzBOaKl-7","executionInfo":{"status":"ok","timestamp":1633768135208,"user_tz":360,"elapsed":146,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","import numpy\n","from keras.callbacks import *\n","from keras.initializers import Constant\n","\n","def create_model_pretrained():\n","    model = Sequential()\n","    #embedding layer\n","    model.add(Embedding(size_of_vocabulary,300,\n","                        input_length=25,\n","                        embeddings_initializer=Constant(embedding_matrix),\n","                        trainable=True))\n","    #lstm layer\n","    model.add(LSTM(128,return_sequences=True,dropout=0.2))\n","\n","    #Global Maxpooling\n","    model.add(GlobalMaxPooling1D())\n","\n","    #Dense Layer\n","    model.add(Dense(64,activation='relu'))\n","    model.add(Dense(len(y_train_all[0]),activation='softmax'))\n","\n","    #Add loss function, metrics, optimizer\n","    # Compile model.  Stochastic gradient descent with Nesterov accelerated\n","    # gradient gives good\n","    # results for this model\n","    sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","    #addingcallbacks\n","    es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=1000)\n","    mc = ModelCheckpoint(model_path_pretrained, monitor='val_accuracy', mode='max', \n","                         save_best_only=True, verbose=2)\n","    \n","    print(model.summary())\n","\n","    return model\n","\n","    \n"],"execution_count":143,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIj2Hq_WHzWl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633766204443,"user_tz":360,"elapsed":126,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"f8dbfad5-7b7a-4587-92e9-26a1714553e1"},"source":["np.argmax(y_train_all, axis=1).shape"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(61,)"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"x1Xonxe-J4uj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iMnxhxP4K3Bi"},"source":["# GRAPH"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAmvKhHEDkVo","executionInfo":{"status":"ok","timestamp":1633767568858,"user_tz":360,"elapsed":127,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"434e6640-cad5-4d2e-818a-6d72185db183"},"source":["print(np.argmax(y_train_all, axis=1))"],"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 4  8  6  8  8  4  3  0  8  9 10  6  8  8  8  5 10  3  6  8  8  3  8  8\n","  5  2  6  8  8  2  1  4  3  5  6  6  2  7  3  4  1  7  8  8  8  1  2  8\n","  4  1  9  5  8  2  8  8 10  1  3  1  7]\n"]}]},{"cell_type":"code","metadata":{"id":"sGjUqrSc9Z7H","colab":{"base_uri":"https://localhost:8080/","height":642},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1633768686572,"user_tz":360,"elapsed":247709,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"3b84ba5a-fcad-41dc-8db1-7f201ee9ae64"},"source":["import matplotlib.pyplot as plt\n","from sklearn.model_selection import cross_val_score\n","from keras.wrappers.scikit_learn import KerasClassifier\n","\n","pretrained = KerasClassifier(build_fn=create_model_pretrained, epochs=300,\n","                             batch_size=5, verbose=2)\n","scratch = KerasClassifier(build_fn=create_model_scratch, epochs=300, \n","                          batch_size=5, verbose=2)\n","bag_of_words = KerasClassifier(build_fn=create_model_bag, epochs=300, \n","                               batch_size=5, verbose=2)\n","classifiers = {'WordEmbeddings (pre-trained)': pretrained,\n","               'WordEmbeddings (from scratch)': scratch}\n","\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n","\n","fig, ax = plt.subplots()\n","for name, model in classifiers.items():\n","    print(name, model)\n","    cv_scores = cross_val_score(model,\n","                                np.array(X_train_all), \n","                                np.argmax(y_train_all, axis=1),\n","                                cv=kfold,\n","                                scoring='accuracy',\n","                                n_jobs=-1,\n","                                verbose=2)\n","    print(cv_scores.mean())\n","    my_lbl = f'{name} {cv_scores.mean():.3f}'\n","    ax.plot(cv_scores, '-o', label=my_lbl) \n","\n","cv_scores = cross_val_score(bag_of_words,\n","                           np.array(X_train_bag),\n","                           np.argmax(y_train_bag, axis=1),\n","                           cv=kfold,\n","                           scoring='accuracy',\n","                           n_jobs=-1,\n","                           verbose=2)\n","\n","my_lbl = f'BOW {cv_scores.mean():.3f}'\n","ax.plot(cv_scores, '-o', label=my_lbl) \n","ax.set_ylim(0.0, 1.1)\n","ax.set_xlabel('Fold')\n","ax.set_ylabel('Accuracy')\n","handles, labels = ax.get_legend_handles_labels()\n","# sort both labels and handles by accuracy\n","labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))   \n","print(f'label: {labels}, handle: {handles}')\n","\n","ax.legend(handles, labels, ncol=1, bbox_to_anchor=(1.04,.5),loc='center left')\n","\n","plt.show() "],"execution_count":146,"outputs":[{"output_type":"stream","name":"stdout","text":["WordEmbeddings (pre-trained) <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f14f5284910>\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n","  % (min_groups, self.n_splits)), UserWarning)\n","[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  1.8min remaining:  4.2min\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.1min finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n","  % (min_groups, self.n_splits)), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["0.7523809523809524\n","WordEmbeddings (from scratch) <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f14f5284d90>\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  1.7min remaining:  4.1min\n"]},{"output_type":"stream","name":"stdout","text":["0.5761904761904761\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.0min finished\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n","  % (min_groups, self.n_splits)), UserWarning)\n","[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    6.0s remaining:   14.0s\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"]},{"output_type":"stream","name":"stdout","text":["label: ('BOW 0.640', 'WordEmbeddings (from scratch) 0.576', 'WordEmbeddings (pre-trained) 0.752'), handle: (<matplotlib.lines.Line2D object at 0x7f14fd500390>, <matplotlib.lines.Line2D object at 0x7f14f5235a90>, <matplotlib.lines.Line2D object at 0x7f14f53dc8d0>)\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPCqgNbp7CpY","executionInfo":{"status":"ok","timestamp":1633768851715,"user_tz":360,"elapsed":72426,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"6bee9fff-d189-4b96-8d4b-70e2e69fe0b3"},"source":["pretrained.fit(np.array(X_train_all), np.argmax(y_train_all, axis=1))\n","pretrained.model.save(os.path.join(intents_path, 'pretrained_embeddings.h5'))\n","\n","#model_save.save(os.path.join(intents_path, 'pretrained_embeddings.h5'))"],"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 25, 300)           26700     \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 25, 128)           219648    \n","_________________________________________________________________\n","global_max_pooling1d_1 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 11)                715       \n","=================================================================\n","Total params: 255,319\n","Trainable params: 255,319\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/300\n","13/13 - 2s - loss: 2.3633 - accuracy: 0.2131\n","Epoch 2/300\n","13/13 - 0s - loss: 2.1717 - accuracy: 0.3279\n","Epoch 3/300\n","13/13 - 0s - loss: 2.0558 - accuracy: 0.3279\n","Epoch 4/300\n","13/13 - 0s - loss: 1.9720 - accuracy: 0.3279\n","Epoch 5/300\n","13/13 - 0s - loss: 1.8932 - accuracy: 0.3279\n","Epoch 6/300\n","13/13 - 0s - loss: 1.7977 - accuracy: 0.3443\n","Epoch 7/300\n","13/13 - 0s - loss: 1.6758 - accuracy: 0.3934\n","Epoch 8/300\n","13/13 - 0s - loss: 1.5713 - accuracy: 0.4590\n","Epoch 9/300\n","13/13 - 0s - loss: 1.4693 - accuracy: 0.5082\n","Epoch 10/300\n","13/13 - 0s - loss: 1.3625 - accuracy: 0.5410\n","Epoch 11/300\n","13/13 - 0s - loss: 1.2179 - accuracy: 0.5246\n","Epoch 12/300\n","13/13 - 0s - loss: 1.1977 - accuracy: 0.5410\n","Epoch 13/300\n","13/13 - 0s - loss: 1.1218 - accuracy: 0.6230\n","Epoch 14/300\n","13/13 - 0s - loss: 0.9792 - accuracy: 0.7049\n","Epoch 15/300\n","13/13 - 0s - loss: 0.9381 - accuracy: 0.7049\n","Epoch 16/300\n","13/13 - 0s - loss: 0.9121 - accuracy: 0.6557\n","Epoch 17/300\n","13/13 - 0s - loss: 0.7671 - accuracy: 0.7049\n","Epoch 18/300\n","13/13 - 0s - loss: 0.7437 - accuracy: 0.7541\n","Epoch 19/300\n","13/13 - 0s - loss: 0.6602 - accuracy: 0.8033\n","Epoch 20/300\n","13/13 - 0s - loss: 0.5885 - accuracy: 0.8852\n","Epoch 21/300\n","13/13 - 0s - loss: 0.5584 - accuracy: 0.8852\n","Epoch 22/300\n","13/13 - 0s - loss: 0.5307 - accuracy: 0.8525\n","Epoch 23/300\n","13/13 - 0s - loss: 0.4799 - accuracy: 0.9180\n","Epoch 24/300\n","13/13 - 0s - loss: 0.4174 - accuracy: 0.9344\n","Epoch 25/300\n","13/13 - 0s - loss: 0.3634 - accuracy: 0.9508\n","Epoch 26/300\n","13/13 - 0s - loss: 0.3212 - accuracy: 0.9672\n","Epoch 27/300\n","13/13 - 0s - loss: 0.2846 - accuracy: 0.9672\n","Epoch 28/300\n","13/13 - 0s - loss: 0.3098 - accuracy: 0.9672\n","Epoch 29/300\n","13/13 - 0s - loss: 0.2228 - accuracy: 0.9836\n","Epoch 30/300\n","13/13 - 0s - loss: 0.1918 - accuracy: 1.0000\n","Epoch 31/300\n","13/13 - 0s - loss: 0.1891 - accuracy: 0.9836\n","Epoch 32/300\n","13/13 - 0s - loss: 0.1508 - accuracy: 1.0000\n","Epoch 33/300\n","13/13 - 0s - loss: 0.1253 - accuracy: 1.0000\n","Epoch 34/300\n","13/13 - 0s - loss: 0.1213 - accuracy: 1.0000\n","Epoch 35/300\n","13/13 - 0s - loss: 0.0984 - accuracy: 1.0000\n","Epoch 36/300\n","13/13 - 0s - loss: 0.0883 - accuracy: 1.0000\n","Epoch 37/300\n","13/13 - 0s - loss: 0.0948 - accuracy: 1.0000\n","Epoch 38/300\n","13/13 - 0s - loss: 0.0801 - accuracy: 1.0000\n","Epoch 39/300\n","13/13 - 0s - loss: 0.0601 - accuracy: 1.0000\n","Epoch 40/300\n","13/13 - 0s - loss: 0.0597 - accuracy: 1.0000\n","Epoch 41/300\n","13/13 - 0s - loss: 0.0612 - accuracy: 1.0000\n","Epoch 42/300\n","13/13 - 0s - loss: 0.0482 - accuracy: 1.0000\n","Epoch 43/300\n","13/13 - 0s - loss: 0.0543 - accuracy: 1.0000\n","Epoch 44/300\n","13/13 - 0s - loss: 0.0418 - accuracy: 1.0000\n","Epoch 45/300\n","13/13 - 0s - loss: 0.0327 - accuracy: 1.0000\n","Epoch 46/300\n","13/13 - 0s - loss: 0.0303 - accuracy: 1.0000\n","Epoch 47/300\n","13/13 - 0s - loss: 0.0287 - accuracy: 1.0000\n","Epoch 48/300\n","13/13 - 0s - loss: 0.0326 - accuracy: 1.0000\n","Epoch 49/300\n","13/13 - 0s - loss: 0.0327 - accuracy: 1.0000\n","Epoch 50/300\n","13/13 - 0s - loss: 0.0280 - accuracy: 1.0000\n","Epoch 51/300\n","13/13 - 0s - loss: 0.0215 - accuracy: 1.0000\n","Epoch 52/300\n","13/13 - 0s - loss: 0.0191 - accuracy: 1.0000\n","Epoch 53/300\n","13/13 - 0s - loss: 0.0196 - accuracy: 1.0000\n","Epoch 54/300\n","13/13 - 0s - loss: 0.0220 - accuracy: 1.0000\n","Epoch 55/300\n","13/13 - 0s - loss: 0.0211 - accuracy: 1.0000\n","Epoch 56/300\n","13/13 - 0s - loss: 0.0203 - accuracy: 1.0000\n","Epoch 57/300\n","13/13 - 0s - loss: 0.0174 - accuracy: 1.0000\n","Epoch 58/300\n","13/13 - 0s - loss: 0.0221 - accuracy: 1.0000\n","Epoch 59/300\n","13/13 - 0s - loss: 0.0180 - accuracy: 1.0000\n","Epoch 60/300\n","13/13 - 0s - loss: 0.0131 - accuracy: 1.0000\n","Epoch 61/300\n","13/13 - 0s - loss: 0.0111 - accuracy: 1.0000\n","Epoch 62/300\n","13/13 - 0s - loss: 0.0126 - accuracy: 1.0000\n","Epoch 63/300\n","13/13 - 0s - loss: 0.0144 - accuracy: 1.0000\n","Epoch 64/300\n","13/13 - 0s - loss: 0.0139 - accuracy: 1.0000\n","Epoch 65/300\n","13/13 - 0s - loss: 0.0127 - accuracy: 1.0000\n","Epoch 66/300\n","13/13 - 0s - loss: 0.0126 - accuracy: 1.0000\n","Epoch 67/300\n","13/13 - 0s - loss: 0.0118 - accuracy: 1.0000\n","Epoch 68/300\n","13/13 - 0s - loss: 0.0081 - accuracy: 1.0000\n","Epoch 69/300\n","13/13 - 0s - loss: 0.0105 - accuracy: 1.0000\n","Epoch 70/300\n","13/13 - 0s - loss: 0.0098 - accuracy: 1.0000\n","Epoch 71/300\n","13/13 - 0s - loss: 0.0104 - accuracy: 1.0000\n","Epoch 72/300\n","13/13 - 0s - loss: 0.0087 - accuracy: 1.0000\n","Epoch 73/300\n","13/13 - 0s - loss: 0.0083 - accuracy: 1.0000\n","Epoch 74/300\n","13/13 - 0s - loss: 0.0086 - accuracy: 1.0000\n","Epoch 75/300\n","13/13 - 0s - loss: 0.0074 - accuracy: 1.0000\n","Epoch 76/300\n","13/13 - 0s - loss: 0.0081 - accuracy: 1.0000\n","Epoch 77/300\n","13/13 - 0s - loss: 0.0076 - accuracy: 1.0000\n","Epoch 78/300\n","13/13 - 0s - loss: 0.0076 - accuracy: 1.0000\n","Epoch 79/300\n","13/13 - 0s - loss: 0.0081 - accuracy: 1.0000\n","Epoch 80/300\n","13/13 - 0s - loss: 0.0069 - accuracy: 1.0000\n","Epoch 81/300\n","13/13 - 0s - loss: 0.0088 - accuracy: 1.0000\n","Epoch 82/300\n","13/13 - 0s - loss: 0.0082 - accuracy: 1.0000\n","Epoch 83/300\n","13/13 - 0s - loss: 0.0066 - accuracy: 1.0000\n","Epoch 84/300\n","13/13 - 0s - loss: 0.0077 - accuracy: 1.0000\n","Epoch 85/300\n","13/13 - 0s - loss: 0.0063 - accuracy: 1.0000\n","Epoch 86/300\n","13/13 - 0s - loss: 0.0061 - accuracy: 1.0000\n","Epoch 87/300\n","13/13 - 0s - loss: 0.0073 - accuracy: 1.0000\n","Epoch 88/300\n","13/13 - 0s - loss: 0.0057 - accuracy: 1.0000\n","Epoch 89/300\n","13/13 - 0s - loss: 0.0064 - accuracy: 1.0000\n","Epoch 90/300\n","13/13 - 0s - loss: 0.0064 - accuracy: 1.0000\n","Epoch 91/300\n","13/13 - 0s - loss: 0.0079 - accuracy: 1.0000\n","Epoch 92/300\n","13/13 - 0s - loss: 0.0058 - accuracy: 1.0000\n","Epoch 93/300\n","13/13 - 0s - loss: 0.0063 - accuracy: 1.0000\n","Epoch 94/300\n","13/13 - 0s - loss: 0.0054 - accuracy: 1.0000\n","Epoch 95/300\n","13/13 - 0s - loss: 0.0043 - accuracy: 1.0000\n","Epoch 96/300\n","13/13 - 0s - loss: 0.0054 - accuracy: 1.0000\n","Epoch 97/300\n","13/13 - 0s - loss: 0.0060 - accuracy: 1.0000\n","Epoch 98/300\n","13/13 - 0s - loss: 0.0056 - accuracy: 1.0000\n","Epoch 99/300\n","13/13 - 0s - loss: 0.0054 - accuracy: 1.0000\n","Epoch 100/300\n","13/13 - 0s - loss: 0.0049 - accuracy: 1.0000\n","Epoch 101/300\n","13/13 - 0s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 102/300\n","13/13 - 0s - loss: 0.0046 - accuracy: 1.0000\n","Epoch 103/300\n","13/13 - 0s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 104/300\n","13/13 - 0s - loss: 0.0041 - accuracy: 1.0000\n","Epoch 105/300\n","13/13 - 0s - loss: 0.0045 - accuracy: 1.0000\n","Epoch 106/300\n","13/13 - 0s - loss: 0.0043 - accuracy: 1.0000\n","Epoch 107/300\n","13/13 - 0s - loss: 0.0047 - accuracy: 1.0000\n","Epoch 108/300\n","13/13 - 0s - loss: 0.0044 - accuracy: 1.0000\n","Epoch 109/300\n","13/13 - 0s - loss: 0.0038 - accuracy: 1.0000\n","Epoch 110/300\n","13/13 - 0s - loss: 0.0054 - accuracy: 1.0000\n","Epoch 111/300\n","13/13 - 0s - loss: 0.0039 - accuracy: 1.0000\n","Epoch 112/300\n","13/13 - 0s - loss: 0.0035 - accuracy: 1.0000\n","Epoch 113/300\n","13/13 - 0s - loss: 0.0043 - accuracy: 1.0000\n","Epoch 114/300\n","13/13 - 0s - loss: 0.0035 - accuracy: 1.0000\n","Epoch 115/300\n","13/13 - 0s - loss: 0.0049 - accuracy: 1.0000\n","Epoch 116/300\n","13/13 - 0s - loss: 0.0044 - accuracy: 1.0000\n","Epoch 117/300\n","13/13 - 0s - loss: 0.0029 - accuracy: 1.0000\n","Epoch 118/300\n","13/13 - 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 119/300\n","13/13 - 0s - loss: 0.0033 - accuracy: 1.0000\n","Epoch 120/300\n","13/13 - 0s - loss: 0.0062 - accuracy: 1.0000\n","Epoch 121/300\n","13/13 - 0s - loss: 0.0029 - accuracy: 1.0000\n","Epoch 122/300\n","13/13 - 0s - loss: 0.0038 - accuracy: 1.0000\n","Epoch 123/300\n","13/13 - 0s - loss: 0.0034 - accuracy: 1.0000\n","Epoch 124/300\n","13/13 - 0s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 125/300\n","13/13 - 0s - loss: 0.0034 - accuracy: 1.0000\n","Epoch 126/300\n","13/13 - 0s - loss: 0.0030 - accuracy: 1.0000\n","Epoch 127/300\n","13/13 - 0s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 128/300\n","13/13 - 0s - loss: 0.0038 - accuracy: 1.0000\n","Epoch 129/300\n","13/13 - 0s - loss: 0.0040 - accuracy: 1.0000\n","Epoch 130/300\n","13/13 - 0s - loss: 0.0032 - accuracy: 1.0000\n","Epoch 131/300\n","13/13 - 0s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 132/300\n","13/13 - 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 133/300\n","13/13 - 0s - loss: 0.0033 - accuracy: 1.0000\n","Epoch 134/300\n","13/13 - 0s - loss: 0.0023 - accuracy: 1.0000\n","Epoch 135/300\n","13/13 - 0s - loss: 0.0031 - accuracy: 1.0000\n","Epoch 136/300\n","13/13 - 0s - loss: 0.0026 - accuracy: 1.0000\n","Epoch 137/300\n","13/13 - 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 138/300\n","13/13 - 0s - loss: 0.0048 - accuracy: 1.0000\n","Epoch 139/300\n","13/13 - 0s - loss: 0.0024 - accuracy: 1.0000\n","Epoch 140/300\n","13/13 - 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 141/300\n","13/13 - 0s - loss: 0.0032 - accuracy: 1.0000\n","Epoch 142/300\n","13/13 - 0s - loss: 0.0036 - accuracy: 1.0000\n","Epoch 143/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 144/300\n","13/13 - 0s - loss: 0.0026 - accuracy: 1.0000\n","Epoch 145/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 146/300\n","13/13 - 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 147/300\n","13/13 - 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 148/300\n","13/13 - 0s - loss: 0.0032 - accuracy: 1.0000\n","Epoch 149/300\n","13/13 - 0s - loss: 0.0027 - accuracy: 1.0000\n","Epoch 150/300\n","13/13 - 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 151/300\n","13/13 - 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 152/300\n","13/13 - 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 153/300\n","13/13 - 0s - loss: 0.0031 - accuracy: 1.0000\n","Epoch 154/300\n","13/13 - 0s - loss: 0.0024 - accuracy: 1.0000\n","Epoch 155/300\n","13/13 - 0s - loss: 0.0024 - accuracy: 1.0000\n","Epoch 156/300\n","13/13 - 0s - loss: 0.0027 - accuracy: 1.0000\n","Epoch 157/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 158/300\n","13/13 - 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 159/300\n","13/13 - 0s - loss: 0.0024 - accuracy: 1.0000\n","Epoch 160/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 161/300\n","13/13 - 0s - loss: 0.0023 - accuracy: 1.0000\n","Epoch 162/300\n","13/13 - 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 163/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 164/300\n","13/13 - 0s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 165/300\n","13/13 - 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 166/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 167/300\n","13/13 - 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 168/300\n","13/13 - 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 169/300\n","13/13 - 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 170/300\n","13/13 - 0s - loss: 0.0021 - accuracy: 1.0000\n","Epoch 171/300\n","13/13 - 0s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 172/300\n","13/13 - 0s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 173/300\n","13/13 - 0s - loss: 0.0027 - accuracy: 1.0000\n","Epoch 174/300\n","13/13 - 0s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 175/300\n","13/13 - 0s - loss: 0.0025 - accuracy: 1.0000\n","Epoch 176/300\n","13/13 - 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 177/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 178/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 179/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 180/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 181/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 182/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 183/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 184/300\n","13/13 - 0s - loss: 0.0023 - accuracy: 1.0000\n","Epoch 185/300\n","13/13 - 0s - loss: 0.0022 - accuracy: 1.0000\n","Epoch 186/300\n","13/13 - 0s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 187/300\n","13/13 - 0s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 188/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 189/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 190/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 191/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 192/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 193/300\n","13/13 - 0s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 194/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 195/300\n","13/13 - 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 196/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 197/300\n","13/13 - 0s - loss: 0.0018 - accuracy: 1.0000\n","Epoch 198/300\n","13/13 - 0s - loss: 0.0028 - accuracy: 1.0000\n","Epoch 199/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 200/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 201/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 202/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 203/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 204/300\n","13/13 - 0s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 205/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 206/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 207/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 208/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 209/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 210/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 211/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 212/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 213/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 214/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 215/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 216/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 217/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 218/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 219/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 220/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 221/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 222/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 223/300\n","13/13 - 0s - loss: 0.0020 - accuracy: 1.0000\n","Epoch 224/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 225/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 226/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 227/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 228/300\n","13/13 - 0s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 229/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 230/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 231/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 232/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 233/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 234/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 235/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 236/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 237/300\n","13/13 - 0s - loss: 0.0015 - accuracy: 1.0000\n","Epoch 238/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 239/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 240/300\n","13/13 - 0s - loss: 9.8303e-04 - accuracy: 1.0000\n","Epoch 241/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 242/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 243/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 244/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 245/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 246/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 247/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 248/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 249/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 250/300\n","13/13 - 0s - loss: 0.0019 - accuracy: 1.0000\n","Epoch 251/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 252/300\n","13/13 - 0s - loss: 0.0017 - accuracy: 1.0000\n","Epoch 253/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 254/300\n","13/13 - 0s - loss: 9.3357e-04 - accuracy: 1.0000\n","Epoch 255/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 256/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 257/300\n","13/13 - 0s - loss: 9.2074e-04 - accuracy: 1.0000\n","Epoch 258/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 259/300\n","13/13 - 0s - loss: 9.1095e-04 - accuracy: 1.0000\n","Epoch 260/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 261/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 262/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 263/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 264/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 265/300\n","13/13 - 0s - loss: 0.0013 - accuracy: 1.0000\n","Epoch 266/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 267/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 268/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 269/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 270/300\n","13/13 - 0s - loss: 9.8321e-04 - accuracy: 1.0000\n","Epoch 271/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 272/300\n","13/13 - 0s - loss: 8.1608e-04 - accuracy: 1.0000\n","Epoch 273/300\n","13/13 - 0s - loss: 8.3841e-04 - accuracy: 1.0000\n","Epoch 274/300\n","13/13 - 0s - loss: 9.9364e-04 - accuracy: 1.0000\n","Epoch 275/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 276/300\n","13/13 - 0s - loss: 9.3928e-04 - accuracy: 1.0000\n","Epoch 277/300\n","13/13 - 0s - loss: 8.3484e-04 - accuracy: 1.0000\n","Epoch 278/300\n","13/13 - 0s - loss: 9.2053e-04 - accuracy: 1.0000\n","Epoch 279/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 280/300\n","13/13 - 0s - loss: 8.2019e-04 - accuracy: 1.0000\n","Epoch 281/300\n","13/13 - 0s - loss: 8.1875e-04 - accuracy: 1.0000\n","Epoch 282/300\n","13/13 - 0s - loss: 8.4440e-04 - accuracy: 1.0000\n","Epoch 283/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 284/300\n","13/13 - 0s - loss: 7.9580e-04 - accuracy: 1.0000\n","Epoch 285/300\n","13/13 - 0s - loss: 9.2474e-04 - accuracy: 1.0000\n","Epoch 286/300\n","13/13 - 0s - loss: 8.0775e-04 - accuracy: 1.0000\n","Epoch 287/300\n","13/13 - 0s - loss: 8.8171e-04 - accuracy: 1.0000\n","Epoch 288/300\n","13/13 - 0s - loss: 9.0054e-04 - accuracy: 1.0000\n","Epoch 289/300\n","13/13 - 0s - loss: 7.0795e-04 - accuracy: 1.0000\n","Epoch 290/300\n","13/13 - 0s - loss: 7.2659e-04 - accuracy: 1.0000\n","Epoch 291/300\n","13/13 - 0s - loss: 9.9240e-04 - accuracy: 1.0000\n","Epoch 292/300\n","13/13 - 0s - loss: 8.3373e-04 - accuracy: 1.0000\n","Epoch 293/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 294/300\n","13/13 - 0s - loss: 0.0010 - accuracy: 1.0000\n","Epoch 295/300\n","13/13 - 0s - loss: 0.0027 - accuracy: 1.0000\n","Epoch 296/300\n","13/13 - 0s - loss: 0.0014 - accuracy: 1.0000\n","Epoch 297/300\n","13/13 - 0s - loss: 0.0012 - accuracy: 1.0000\n","Epoch 298/300\n","13/13 - 0s - loss: 0.0016 - accuracy: 1.0000\n","Epoch 299/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n","Epoch 300/300\n","13/13 - 0s - loss: 0.0011 - accuracy: 1.0000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRvxPM2qSJS7","executionInfo":{"status":"ok","timestamp":1633767036168,"user_tz":360,"elapsed":146,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"b2f75993-035c-4158-b8d1-a79ce61b9b09"},"source":["print(np.argmax(y_train_bag, axis=1))"],"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 8  2  2  1  6  2  8  8  8 10  8  3  8  8  8  8  6  1  9  4  7  6  5  8\n","  1  7  6  8  4  8 10  5  8  4  8  3 10  3  4  3  7  5  2  8  0  8  8  8\n","  8  9  6  2  1  3  5  4  8  1  3  6  1]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZccyZjDLwQ8t","executionInfo":{"status":"ok","timestamp":1633768982480,"user_tz":360,"elapsed":1219,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"0342d3fc-7e6b-407d-c1a9-696a28ab332f"},"source":["from keras import models\n","model = models.load_model(os.path.join(intents_path, 'pretrained_embeddings.h5'))\n","tokenizer = pickle.load(open(os.path.join(intents_path, 'tokenizer.pickle'), 'rb'))\n","tokenizer = tokenizer.texts_to_sequences(['Can you hear me?'])\n","sequence = pad_sequences(tokenizer, maxlen=25)\n","print(sequence)\n","res = model.predict(sequence)[0]\n","print(res)"],"execution_count":150,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  2 46\n","  14]]\n","[5.87864133e-06 1.84937860e-04 6.06553622e-05 9.99703228e-01\n"," 1.85693461e-05 1.23754335e-05 2.72331079e-07 5.24416782e-06\n"," 1.63249553e-10 8.77201546e-06 4.73464787e-08]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJX0WzGtoorB","executionInfo":{"status":"ok","timestamp":1633767048535,"user_tz":360,"elapsed":144,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"4fe45f7d-43dc-4c9d-c6ee-31c268480a0f"},"source":["print(X_train)"],"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["[array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  1, 12,  2,  3, 41,  4, 24], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0, 15,  2, 40, 14, 17,  4, 13], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,\n","       78, 79,  4, 13, 80,  3, 20, 81], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0, 61,  9,  2], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 12,  3, 16,  8, 13], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 54], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 12,  2,  3, 41, 72], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6,  9,  2, 30], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 19, 67, 36,  7, 11], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 88], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  6, 15,  1, 17,  4, 13], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1, 33,  3, 52], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, 38, 14,  4, 22, 23], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 32, 73, 74,  7, 11], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1, 42,  7, 11], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 19, 18,  3, 66,  2], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6,  9,  2, 50], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  2,  9, 56, 57], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  1, 12,  8, 21], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6, 10, 31, 18], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  6, 32,  2, 51], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  4, 76, 10, 25], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 15,  2, 46, 14], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0, 27, 45], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  1,  5,  2,  3, 85], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 38, 14, 65, 37], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, 20, 14,  3,  7, 39], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1,  5,  3, 17,  4, 13], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  1,  5,  4, 22, 23], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0, 36, 62, 19,  1, 63], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  6,  9,  2, 47, 30], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 27], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 60, 10,  7, 35], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0, 55,  3,  2, 34], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  1, 42,  2], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  4, 24, 10, 25], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 43], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 87], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0,  0,  0, 53], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1,  5,  3, 16,  8, 11], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0, 28,  2, 34], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  0, 29,  9,  2], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  0,  4, 69, 10, 25], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  0,  1,  5,  8, 21, 75], dtype=int32), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","        0,  0,  1, 12,  3, 16,  8, 11], dtype=int32)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"a68HVsZmL615"},"source":["# Fit Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMXzGUQEL2fm","executionInfo":{"status":"ok","timestamp":1633714094585,"user_tz":360,"elapsed":6637,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"684f4ce4-393e-4849-ca8c-c35501bc2b0c"},"source":["from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=5,shuffle=True, random_state=1)\n","lst_accu_stratified = []\n","for train_index, test_index in skf.split(X_all_seq, y_all):\n","    x_train_fold, x_test_fold = X_all_seq[train_index], X_all_seq[test_index]\n","    y_train_fold, y_test_fold = y_all[train_index], y_all[test_index]\n","    print(x_train_fold, y_train_fold)\n","    model.fit(np.array(x_train_fold),np.array(y_train_fold),batch_size=128,epochs=10,\n","              validation_data=(np.array(x_test_fold), np.array(y_test_fold)),\n","              verbose=1,callbacks=[es,mc])\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[[ 0  0  0 ...  0  0 27]\n"," [ 0  0  0 ...  3 28  2]\n"," [ 0  0  0 ...  2 46 14]\n"," ...\n"," [ 0  0  0 ...  1 42  2]\n"," [ 0  0  0 ...  0  0 87]\n"," [ 0  0  0 ...  0  0 88]] [ 3  3  3  3  1  1  1  1  1  2  2  2  2  0  9  9  5  5  5  4  4  4  4  8\n","  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  6  6  6  6  6  7  7 10 10]\n","Epoch 1/10\n","1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00 - acc: 0.1042 - val_loss: 0.0000e+00 - val_acc: 0.0769\n","\n","Epoch 00001: val_acc improved from -inf to 0.07692, saving model to /content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models/best_model_scratch.h5\n","Epoch 2/10\n","1/1 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - acc: 0.1042 - val_loss: 0.0000e+00 - val_acc: 0.0769\n","\n","Epoch 00002: val_acc did not improve from 0.07692\n","Epoch 3/10\n","1/1 [==============================] - 0s 77ms/step - loss: 0.0000e+00 - acc: 0.1042 - val_loss: 0.0000e+00 - val_acc: 0.0769\n","\n","Epoch 00003: val_acc did not improve from 0.07692\n","Epoch 4/10\n","1/1 [==============================] - 0s 77ms/step - loss: 0.0000e+00 - acc: 0.1042 - val_loss: 0.0000e+00 - val_acc: 0.0769\n","\n","Epoch 00004: val_acc did not improve from 0.07692\n","Epoch 00004: early stopping\n","[[ 0  0  0 ...  0  0 43]\n"," [ 0  0  0 ...  3 28  2]\n"," [ 0  0  0 ...  0 27 45]\n"," ...\n"," [ 0  0  0 ... 26 26 26]\n"," [ 0  0  0 ...  0  0 87]\n"," [ 0  0  0 ...  0  0 88]] [ 3  3  3  3  3  1  1  1  1  2  2  2  2  0  9  9  5  5  5  4  4  4  4  8\n","  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  6  6  6  6  6  7  7 10 10\n"," 10]\n","Epoch 1/10\n","1/1 [==============================] - 0s 124ms/step - loss: 0.0000e+00 - acc: 0.0816 - val_loss: 0.0000e+00 - val_acc: 0.1667\n","\n","Epoch 00001: val_acc improved from 0.07692 to 0.16667, saving model to /content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models/best_model_scratch.h5\n","Epoch 2/10\n","1/1 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - acc: 0.0816 - val_loss: 0.0000e+00 - val_acc: 0.1667\n","\n","Epoch 00002: val_acc did not improve from 0.16667\n","Epoch 3/10\n","1/1 [==============================] - 0s 75ms/step - loss: 0.0000e+00 - acc: 0.0816 - val_loss: 0.0000e+00 - val_acc: 0.1667\n","\n","Epoch 00003: val_acc did not improve from 0.16667\n","Epoch 4/10\n","1/1 [==============================] - 0s 82ms/step - loss: 0.0000e+00 - acc: 0.0816 - val_loss: 0.0000e+00 - val_acc: 0.1667\n","\n","Epoch 00004: val_acc did not improve from 0.16667\n","Epoch 00004: early stopping\n","[[ 0  0  0 ...  0  0 27]\n"," [ 0  0  0 ...  0  0 43]\n"," [ 0  0  0 ...  3 28  2]\n"," ...\n"," [ 0  0  0 ... 26 26 26]\n"," [ 0  0  0 ...  0  0 87]\n"," [ 0  0  0 ...  0  0 88]] [ 3  3  3  3  3  1  1  1  1  1  2  2  2  2  9  9  5  5  5  4  4  4  4  8\n","  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  6  6  6  6  6  7  7 10 10\n"," 10]\n","Epoch 1/10\n","1/1 [==============================] - 0s 105ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00001: val_acc did not improve from 0.16667\n","Epoch 2/10\n","1/1 [==============================] - 0s 77ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00002: val_acc did not improve from 0.16667\n","Epoch 3/10\n","1/1 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00003: val_acc did not improve from 0.16667\n","Epoch 4/10\n","1/1 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00004: val_acc did not improve from 0.16667\n","Epoch 00004: early stopping\n","[[ 0  0  0 ...  0  0 27]\n"," [ 0  0  0 ...  0  0 43]\n"," [ 0  0  0 ...  0 27 45]\n"," ...\n"," [ 0  0  0 ...  2  3 85]\n"," [ 0  0  0 ... 26 26 26]\n"," [ 0  0  0 ...  0  0 88]] [ 3  3  3  3  3  1  1  1  1  1  2  2  2  2  0  9  5  5  5  4  4  4  4  8\n","  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  6  6  6  6  6  7  7  7 10\n"," 10]\n","Epoch 1/10\n","1/1 [==============================] - 0s 104ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00001: val_acc did not improve from 0.16667\n","Epoch 2/10\n","1/1 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00002: val_acc did not improve from 0.16667\n","Epoch 3/10\n","1/1 [==============================] - 0s 78ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00003: val_acc did not improve from 0.16667\n","Epoch 4/10\n","1/1 [==============================] - 0s 77ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00004: val_acc did not improve from 0.16667\n","Epoch 00004: early stopping\n","[[ 0  0  0 ...  0  0 27]\n"," [ 0  0  0 ...  0  0 43]\n"," [ 0  0  0 ...  3 28  2]\n"," ...\n"," [ 0  0  0 ...  2  3 85]\n"," [ 0  0  0 ... 26 26 26]\n"," [ 0  0  0 ...  0  0 87]] [ 3  3  3  3  3  1  1  1  1  1  2  2  2  2  0  9  5  5  5  5  4  4  4  4\n","  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  6  6  6  6  7  7  7 10\n"," 10]\n","Epoch 1/10\n","1/1 [==============================] - 0s 115ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00001: val_acc did not improve from 0.16667\n","Epoch 2/10\n","1/1 [==============================] - 0s 80ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00002: val_acc did not improve from 0.16667\n","Epoch 3/10\n","1/1 [==============================] - 0s 74ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00003: val_acc did not improve from 0.16667\n","Epoch 4/10\n","1/1 [==============================] - 0s 83ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.0833\n","\n","Epoch 00004: val_acc did not improve from 0.16667\n","Epoch 00004: early stopping\n"]}]},{"cell_type":"code","metadata":{"id":"OK_ku-ekGqG_","colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"status":"error","timestamp":1633765039445,"user_tz":360,"elapsed":179,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"2445a10d-a353-4315-ff16-3d69e849dc01"},"source":["\n","# convert for k-fold sampling\n","X, y = X_all, y_all\n","\n","from sklearn.model_selection import cross_val_score\n","\n","model \n","# Tokenize the sentences\n","#tokenize\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","tokenizer = Tokenizer()\n","for train, val in skf.split(X, y):\n","    print(f'train  - {np.bincount(y[train])} | test - {np.bincount(y[test])}')\n","    # preparing vocabulary\n","    tokenizer.fit_on_texts(list(X[train]))\n","    # convert text into integer sequences\n","    x_tr_seq.extend(tokenizer.texts_to_sequences(X[train]))\n","    x_val_seq.extend(tokenizer.texts_to_sequences(X[val]))\n","    y_tr.extend(y[train])\n","    y_val.extend(y[val])\n","   \n","    #print(x_tr_seq[:5])\n","    #print(x_val_seq[:5])\n","    #print(x_tr_seq)\n","    # padding to prepare sequences of same length\n","    #all_sequences = pad_sequences(all_sequences, maxlen=100)\n","x_tr_seq = pad_sequences(x_tr_seq, maxlen=100)\n","x_val_seq = pad_sequences(x_val_seq, maxlen=100)\n","size_of_vocabulary = len(tokenizer.word_index) + 1\n","print(tokenizer.word_index)\n","print(f' Size of vocab: {size_of_vocabulary}')\n","    #print(all_patterns.shape)\n","    #print(label_encoded_Y.shape)\n"],"execution_count":305,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-305-6cc0e0dd3368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train  - {np.bincount(y[train])} | test - {np.bincount(y[test])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# preparing vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'skf' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"QhB-JGt4amCr","executionInfo":{"elapsed":169,"status":"ok","timestamp":1633136630122,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"outputId":"a4da8ab4-1470-4433-9f8c-e2ca08ccd382"},"source":["print(len(x_tr_seq))\n","print(len(y_tr))\n","print(len(x_val_seq))\n","print(len(y_val))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["122\n","122\n","61\n","61\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UofjkfFcjvM","executionInfo":{"elapsed":467,"status":"ok","timestamp":1633136851410,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"outputId":"43e67982-db85-45bb-84b3-2fd8ae95834c"},"source":["MODEL_NAME1 = 'best_model_scratch.h5'\n","MODEL_NAME2 = 'best_model_pretrained.h5'\n","model_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models'\n","\n","# build two different NLP models of the same architecture.  The first learns\n","# embeddings from scratch the second uses pretrained word embeddings\n","from keras.models import *\n","from keras.layers import *\n","from keras.callbacks import *\n","\n","#training = os.path.join(data_path, TRAIN_CSV)\n","#validation = os.path.join(data_path, VALID_CSV)\n","model_path_scratch = os.path.join(model_path, MODEL_NAME1)\n","model_path_pretrained = os.path.join(model_path, MODEL_NAME2)\n","\n","model = Sequential()\n","# Create model with 3 layers.  First layer 128 neurons, second layer 64 neurons\n","# and 3rd output layer contains number of neurons equal to number of intents to\n","# predict\n","# output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model.  Stochastic gradient descent with Nesterov accelerated\n","# gradient gives good\n","# results for this model\n","sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#embedding layer\n","model.add(Embedding(size_of_vocabulary,300,\n","                    weights=[embedding_matrix],\n","                    input_length=100,trainable=False))\n","\n","#lstm layer\n","model.add(LSTM(128,return_sequences=True,dropout=0.2))\n","\n","#Global Maxpooling\n","model.add(GlobalMaxPooling1D())\n","\n","model.add(Dense(64,activation='relu'))\n","model.add(Dense(len(,activation='softmax'))\n","\n","# add loss, metrics, optimizer\n","model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n","\n","# adding callbacks\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n","mc = ModelCheckpoint(model_path_pretrained, monitor='val_acc', mode='max', \n","                     save_best_only=True,verbose=1)\n","\n","#print summary of model\n","print(model.summary())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 100, 300)          26700     \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 100, 128)          219648    \n","_________________________________________________________________\n","global_max_pooling1d_4 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 254,669\n","Trainable params: 227,969\n","Non-trainable params: 26,700\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"id":"8AhgAx6ygln0"},"source":["y_tr = np.array(y_tr)\n","y_val = np.array(y_val)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLB8RMNQdv2n","executionInfo":{"elapsed":1713,"status":"ok","timestamp":1633137091964,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"outputId":"e60cc3ac-e300-4c08-9e5a-25151839f5c9"},"source":["history = model.fit(np.array(x_tr_seq),np.array(y_tr),batch_size=128,epochs=10,\n","                    validation_data=(np.array(x_val_seq),np.array(y_val)),\n","                    verbose=1,callbacks=[es,mc])\n","\n","\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1/1 [==============================] - 0s 378ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00001: val_acc did not improve from 0.09836\n","Epoch 2/10\n","1/1 [==============================] - 0s 329ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00002: val_acc did not improve from 0.09836\n","Epoch 3/10\n","1/1 [==============================] - 0s 353ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00003: val_acc did not improve from 0.09836\n","Epoch 4/10\n","1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00004: val_acc did not improve from 0.09836\n","Epoch 00004: early stopping\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MpI1AxDkT4Ey","executionInfo":{"elapsed":153,"status":"ok","timestamp":1633133016751,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"outputId":"125a11d4-4772-4d64-dec1-acc803c5f7bf"},"source":["\n","from sklearn.model_selection import StratifiedKFold, KFold\n","import numpy as np\n","X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n","print(X)\n","print(y)\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 1 1 1 1 1]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj3xZAWvQWPg","executionInfo":{"elapsed":167,"status":"ok","timestamp":1633132291327,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"outputId":"5b970657-9b61-400d-9f39-58ff6930443d"},"source":["#tokenize\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# Tokenize the sentences\n","tokenizer = Tokenizer()\n","# preparing vocabulary\n","tokenizer.fit_on_texts(list(all_patterns))\n","# convert text into integer sequences\n","all_sequences = tokenizer.texts_to_sequences(all_patterns)\n","print(all_sequences)\n","# padding to prepare sequences of same length\n","all_sequences = pad_sequences(all_sequences, maxlen=100)\n","size_of_vocabulary = len(tokenizer.word_index) + 1\n","print(f' Size of vocab: {size_of_vocabulary}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[[27], [43], [44, 3, 28, 2], [27, 45], [15, 2, 46, 14], [29, 9, 2], [6, 9, 2, 30], [6, 9, 2, 47, 30], [48, 31, 18, 49], [6, 9, 2, 50], [6, 32, 2, 51], [6, 10, 31, 18], [1, 33, 3, 52], [53], [54], [28, 2, 34], [55, 3, 2, 34], [2, 9, 56, 57], [58], [59, 2], [60, 10, 7, 35], [35], [61, 9, 2], [36, 62, 19, 1, 63], [15, 1, 64, 3, 7, 37], [38, 14, 65, 37], [1, 5, 7, 39], [1, 19, 18, 3, 66, 2], [20, 14, 3, 7, 39], [1, 19, 67, 36, 7, 11], [1, 12, 3, 16, 8, 11], [1, 12, 8, 21], [1, 12, 3, 20, 68, 40], [1, 5, 4, 22, 23], [4, 24, 10, 25], [4, 69, 10, 25], [4, 24, 70, 71], [1, 12, 2, 3, 41, 72], [1, 32, 73, 74, 7, 11], [1, 5, 4, 22, 23], [1, 5, 8, 21, 75], [38, 14, 4, 22, 23], [1, 42, 7, 11], [4, 76, 10, 25], [1, 12, 2, 3, 41, 4, 24], [1, 5, 8, 21], [1, 12, 3, 16, 8, 13], [1, 5, 3, 16, 8, 11], [1, 33, 8, 11, 77, 1, 5, 3, 16], [6, 15, 1, 17, 4, 13], [29, 10, 4, 13], [6, 78, 79, 4, 13, 80, 3, 20, 81], [1, 5, 3, 17, 4, 13], [15, 2, 40, 14, 17, 4, 13], [1, 5, 3, 17, 4, 82], [83, 84], [1, 42, 2], [1, 5, 2, 3, 85], [86, 26, 26, 26], [87], [88]]\n"," Size of vocab: 89\n"]}]},{"cell_type":"code","metadata":{"id":"jaa2dmVhK3tB"},"source":["\n","\n","     for pattern in intent['patterns']:\n","          w = nltk.word_tokenize(pattern)\n","          words.extend(w)\n","\n","          documents.append((w, intent['tag']))\n","\n","          if intent['tag'] not in classes:\n","               classes.append(intent['tag'])\n","\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n","\n","classes = sorted(list(set(classes)))\n","\n","print(len(documents), 'documents')\n","print(len(classes), 'classes', classes)\n","print(len(words), 'unique lemmatized words', words)\n","\n","pickle.dump(words,open(os.path.join(intents_path, 'intents_words.pkl'),'wb'))\n","pickle.dump(classes,open(os.path.join(intents_path, 'intents_classes.pkl'),'wb'))\n","\n","# init training data\n","training = []\n","output_empty = [0] * len(classes)\n","for doc in documents:\n","    bag = []\n","    # english representation of words\n","    pattern_words = doc[0]\n","    # convert to lowercase and lemmatized versions\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","\n","    from keras.preprocessing.text import Tokenizer\n","    from keras.preprocessing.sequence import pad_sequences\n","\n","    #Tokenize the sentence \n","    for w in words:\n","         bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])\n","\n","random.shuffle(training)\n","training = np.array(training)\n","# create train and test lists.  X - patterns, y - intents\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print('Training data created')\n","\n","# Create model with 3 layers.  First layer 128 neurons, second layer 64 neurons\n","# and 3rd output layer contains number of neurons equal to number of intents to\n","# predict\n","# output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model.  Stochastic gradient descent with Nesterov accelerated\n","# gradient gives good\n","# results for this model\n","sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","# fitting and saving the model\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=1000, batch_size=5, verbose=1)\n","model.save(os.path.join(intents_path, 'intents_chatbot_model.h5'), hist)\n","\n","print('model created')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_h3u5oBVOWG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_WHER_Pdr9B"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYogec4BJBFT"},"source":[""],"execution_count":null,"outputs":[]}]}