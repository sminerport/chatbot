{"cells":[{"cell_type":"markdown","metadata":{"id":"wFE1Byn9bRGk"},"source":["# Download Embeddings"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497990,"status":"ok","timestamp":1633678495966,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"PhdglgD9YENs","outputId":"4dddf205-204e-48e8-f216-b1e2715af384"},"outputs":[{"name":"stdout","output_type":"stream","text":["**************************\n","  Downloading zip file\n","  \u003e_\u003c  Please wait \u003e_\u003c \n","**************************\n"]},{"name":"stderr","output_type":"stream","text":["4251502it [06:55, 10235.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["  Download completed ;) :\n","1. Extracting /content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.zip file\n"]}],"source":["import os\n","import tqdm\n","import requests\n","import zipfile\n","\n","URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n","\n","def fetch_data(url=URL,target_file='/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.zip', delete_zip=False):\n","    # if dataset exists exit\n","    if os.path.isfile(target_file):\n","        print('datasets already downloaded')\n","        return\n","\n","        #download (large) zip file\n","    #for large https request on stream mode to avoid out of memory issues\n","    #see : http://masnun.com/2016/09/18/python-using-the-requests-module-to-download-large-files-efficiently.html\n","    print(\"**************************\")\n","    print(\"  Downloading zip file\")\n","    print(\"  \u003e_\u003c  Please wait \u003e_\u003c \")\n","    print(\"**************************\")\n","    response = requests.get(url, stream=True)\n","    #read chunk by chunk\n","    handle = open(target_file, \"wb\")\n","    for chunk in tqdm.tqdm(response.iter_content(chunk_size=512)):\n","        if chunk:  \n","            handle.write(chunk)\n","    handle.close()  \n","    print(\"  Download completed ;) :\") \n","    #extract zip_file\n","    zf = zipfile.ZipFile(target_file)\n","    print(\"1. Extracting {} file\".format(target_file))\n","    zf.extractall(path='/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings')\n","    if delete_zip:\n","        print(\"2. Deleting {} file\".format(dataset_name+\".zip\"))\n","        os.remove(path=zip_file)\n","\n","fetch_data()"]},{"cell_type":"markdown","metadata":{"id":"olOEGjoHK_oM"},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":5681,"status":"ok","timestamp":1633678843418,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"BhS9gqsQQcHk","outputId":"0f99595b-e2fe-47f8-aba3-ade86501b565"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}],"source":["import os\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import json\n","import pickle\n","\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers import SGD\n","import random\n","from sklearn import preprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"CD7iDv_WLEm4"},"source":["# Set Variables"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":555,"status":"ok","timestamp":1633678895190,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"IEoYFgQlK66T"},"outputs":[],"source":["MODEL_NAME1 = 'best_model_scratch.h5'\n","MODEL_NAME2 = 'best_model_pretrained.h5'\n","model_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models'\n","\n","model_path_scratch = os.path.join(model_path, MODEL_NAME1)\n","model_path_pretrained = os.path.join(model_path, MODEL_NAME2)\n","\n","intents_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/data/intents'\n","\n","# inference model variables\n","inference_load_intents_from = os.path.join(intents_path, 'intents_job_intents.json')\n","\n","words = []\n","tags = []\n","documents = []\n","all_patterns = []\n","all_tags = []\n","label_encoded_Y = []\n","x_tr_seq = []\n","x_val_seq = []\n","y_tr = []\n","y_val = []\n","ignore_words = ['?', '!']"]},{"cell_type":"markdown","metadata":{"id":"MFxx-KBDCPWc"},"source":["# Load JSON"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"executionInfo":{"elapsed":613,"status":"ok","timestamp":1633678910449,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"9JDcFJogdKsd"},"outputs":[],"source":["data_file = open(inference_load_intents_from, encoding='cp1252').read()\n","intents = json.loads(data_file)"]},{"cell_type":"markdown","metadata":{"id":"yOioSpstC1P7"},"source":["## Read in patterns and tags\n","\n","Patterns are the user input (i.e., 'Hi,' 'How are you?').\n","\n","Nothing is tokenized here."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":557,"status":"ok","timestamp":1633678916475,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"N8Yd42VXCtgO","outputId":"7bdb1cba-907a-433b-de74-932c254c0b25"},"outputs":[{"name":"stdout","output_type":"stream","text":["['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'feeling', 'feeling', 'feeling', 'feeling', 'feeling', 'feeling', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'compliment', 'thanks', 'thanks', 'name', 'name', 'name', 'name', 'manager', 'manager', 'manager', 'manager', 'manager', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'profane', 'profane', 'profane', 'tracking', 'tracking', 'tracking']\n","['Hello', 'Hi', 'Good to see you.', 'Hello, there!', 'Can you hear me?', 'Where are you?', 'How are you today?', 'How are you doing today?', \"How's it going?'\", 'How are you feeling?', 'How do you feel?', 'How is it going?', 'I have to go.', 'Bye', 'Goodbye', 'See you later', 'Talk to you later', 'You are very helpful', 'Thanks', 'Thank you', 'What is your name?', 'Name?', 'Who are you?', 'With whom am I speaking?', 'Can I speak to your manager?', 'Give me the manager!', 'I want your supervisor.', 'I am going to report you.', 'Get me to your supervisor.', 'I am unhappy with your product.', 'I need to return a product.', 'I need a refund!', 'I need to get some help.', 'I want my money back.', 'My computer is broken.', 'My equipment is broken.', 'My computer needs fixed.', 'I need you to fix something', 'I do not like your product', 'I want my money back.', 'I want a refund, now!', 'Give me my money back!', 'I hate your product.', 'My device is broken.', 'I need you to fix my computer', 'I want a refund', 'I need to return a package.', 'I want to return a product.', 'I have a product that I want to return.', 'How can I track my package?', 'Where is my package?', 'How long will my package take to get here?', 'I want to track my package.', 'Can you help me track my package?', 'I want to track my shipment.', 'Drop dead.', 'I hate you.', 'I want you to die.', '1983-2343-2343-2343', '1234509873234323', '0983834298342341']\n"]}],"source":["# print classes\n","for intent in intents['intents']:\n","    all_patterns.extend(intent['patterns'])\n","    for pattern in intent['patterns']:\n","        all_tags.append(intent['tag'])\n","\n","print(all_tags)\n","print(all_patterns)"]},{"cell_type":"markdown","metadata":{"id":"a1RyLAppDkf7"},"source":["## Encode Tags\n"]},{"cell_type":"markdown","metadata":{"id":"XMGIsSR_D-Dm"},"source":["\n","### Fit"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":583,"status":"ok","timestamp":1633678922675,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"ey2tdhgWDCyq","outputId":"00865fa3-70c5-4c20-a973-917fa5e63d7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of classes: 11\n"]}],"source":["# create label encoder\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","# fit on all tags from JSON file\n","le.fit(all_tags)\n","print(f'Number of classes: {len(list(le.classes_))}')"]},{"cell_type":"markdown","metadata":{"id":"A38hiFKfEoh7"},"source":["### Transform"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1633678927744,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"nktR6B85FKbT","outputId":"d6f8df92-f214-42b0-e58f-6e81dc7581fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label_encoded_Y: [ 3  3  3  3  3  3  1  1  1  1  1  1  2  2  2  2  2  0  9  9  5  5  5  5\n","  4  4  4  4  4  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n","  8  6  6  6  6  6  6  7  7  7 10 10 10]\n","Label_encoded_Y bincount: [ 1  6  5  6  5  4  6  3 20  2  3]\n"]}],"source":["label_encoded_Y = le.transform(all_tags)\n","print(f'Label_encoded_Y: {label_encoded_Y}')\n","print(f'Label_encoded_Y bincount: {np.bincount(label_encoded_Y)}')"]},{"cell_type":"markdown","metadata":{"id":"bwhM8NHIGtFu"},"source":["## Create x_all, y_all"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1633678946333,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"48px4VM8DsZD","outputId":"20204c14-e711-4520-c05a-45aec76d6fe6"},"outputs":[{"name":"stdout","output_type":"stream","text":["X all shape: (61,)\n","Y all shape: (61,)\n"]}],"source":["X_all = np.asarray(all_patterns)\n","y_all = np.asarray(label_encoded_Y)\n","print(f'X all shape: {X_all.shape}')\n","print(f'Y all shape: {y_all.shape}')"]},{"cell_type":"markdown","metadata":{"id":"YWzLTI7BJEiK"},"source":["# Tokenize"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165,"status":"ok","timestamp":1633680875541,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"k4leW3FIJHnj","outputId":"83e3046a-6470-4370-e919-04a68ac177ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'i': 1, 'you': 2, 'to': 3, 'my': 4, 'want': 5, 'how': 6, 'your': 7, 'a': 8, 'are': 9, 'is': 10, 'product': 11, 'need': 12, 'package': 13, 'me': 14, 'can': 15, 'return': 16, 'track': 17, 'going': 18, 'am': 19, 'get': 20, 'refund': 21, 'money': 22, 'back': 23, 'computer': 24, 'broken': 25, '2343': 26, 'hello': 27, 'see': 28, 'where': 29, 'today': 30, 'it': 31, 'do': 32, 'have': 33, 'later': 34, 'name': 35, 'with': 36, 'manager': 37, 'give': 38, 'supervisor': 39, 'help': 40, 'fix': 41, 'hate': 42, 'hi': 43, 'good': 44, 'there': 45, 'hear': 46, 'doing': 47, \"how's\": 48, \"'\": 49, 'feeling': 50, 'feel': 51, 'go': 52, 'bye': 53, 'goodbye': 54, 'talk': 55, 'very': 56, 'helpful': 57, 'thanks': 58, 'thank': 59, 'what': 60, 'who': 61, 'whom': 62, 'speaking': 63, 'speak': 64, 'the': 65, 'report': 66, 'unhappy': 67, 'some': 68, 'equipment': 69, 'needs': 70, 'fixed': 71, 'something': 72, 'not': 73, 'like': 74, 'now': 75, 'device': 76, 'that': 77, 'long': 78, 'will': 79, 'take': 80, 'here': 81, 'shipment': 82, 'drop': 83, 'dead': 84, 'die': 85, '1983': 86, '1234509873234323': 87, '0983834298342341': 88}\n","[[27], [43], [44, 3, 28, 2], [27, 45], [15, 2, 46, 14], [29, 9, 2], [6, 9, 2, 30], [6, 9, 2, 47, 30], [48, 31, 18, 49], [6, 9, 2, 50], [6, 32, 2, 51], [6, 10, 31, 18], [1, 33, 3, 52], [53], [54], [28, 2, 34], [55, 3, 2, 34], [2, 9, 56, 57], [58], [59, 2], [60, 10, 7, 35], [35], [61, 9, 2], [36, 62, 19, 1, 63], [15, 1, 64, 3, 7, 37], [38, 14, 65, 37], [1, 5, 7, 39], [1, 19, 18, 3, 66, 2], [20, 14, 3, 7, 39], [1, 19, 67, 36, 7, 11], [1, 12, 3, 16, 8, 11], [1, 12, 8, 21], [1, 12, 3, 20, 68, 40], [1, 5, 4, 22, 23], [4, 24, 10, 25], [4, 69, 10, 25], [4, 24, 70, 71], [1, 12, 2, 3, 41, 72], [1, 32, 73, 74, 7, 11], [1, 5, 4, 22, 23], [1, 5, 8, 21, 75], [38, 14, 4, 22, 23], [1, 42, 7, 11], [4, 76, 10, 25], [1, 12, 2, 3, 41, 4, 24], [1, 5, 8, 21], [1, 12, 3, 16, 8, 13], [1, 5, 3, 16, 8, 11], [1, 33, 8, 11, 77, 1, 5, 3, 16], [6, 15, 1, 17, 4, 13], [29, 10, 4, 13], [6, 78, 79, 4, 13, 80, 3, 20, 81], [1, 5, 3, 17, 4, 13], [15, 2, 40, 14, 17, 4, 13], [1, 5, 3, 17, 4, 82], [83, 84], [1, 42, 2], [1, 5, 2, 3, 85], [86, 26, 26, 26], [87], [88]]\n","\u003cclass 'list'\u003e\n"]}],"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(list(X_all))\n","print(tokenizer.word_index)\n","X_all_seq = tokenizer.texts_to_sequences(X_all)\n","print(X_all_seq)\n","print(type(X_all_seq))"]},{"cell_type":"markdown","metadata":{"id":"uVmE5G9RJyCp"},"source":["### Pad"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1633680965237,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"M1tA5wqBJ0HS","outputId":"be3c7b21-c719-4aaa-987f-077dcdd51861"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'numpy.ndarray'\u003e\n","Shape (X_all): (61, 10)\n"]}],"source":["# padding to prepare sequences of same length\n","X_all_seq = pad_sequences(X_all_seq, maxlen=10)\n","#print(X_all_seq)\n","#type is now a numpy.ndarray\n","print(type(X_all_seq))\n","print(f'Shape (X_all): {X_all_seq.shape}')"]},{"cell_type":"markdown","metadata":{"id":"J8ateuv7KQ7T"},"source":["# Vocab Size"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1633678970239,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"LrgIj7a4KQ7T","outputId":"5c043a81-e9a2-48d5-f910-ae0f94948c1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'i': 1, 'you': 2, 'to': 3, 'my': 4, 'want': 5, 'how': 6, 'your': 7, 'a': 8, 'are': 9, 'is': 10, 'product': 11, 'need': 12, 'package': 13, 'me': 14, 'can': 15, 'return': 16, 'track': 17, 'going': 18, 'am': 19, 'get': 20, 'refund': 21, 'money': 22, 'back': 23, 'computer': 24, 'broken': 25, '2343': 26, 'hello': 27, 'see': 28, 'where': 29, 'today': 30, 'it': 31, 'do': 32, 'have': 33, 'later': 34, 'name': 35, 'with': 36, 'manager': 37, 'give': 38, 'supervisor': 39, 'help': 40, 'fix': 41, 'hate': 42, 'hi': 43, 'good': 44, 'there': 45, 'hear': 46, 'doing': 47, \"how's\": 48, \"'\": 49, 'feeling': 50, 'feel': 51, 'go': 52, 'bye': 53, 'goodbye': 54, 'talk': 55, 'very': 56, 'helpful': 57, 'thanks': 58, 'thank': 59, 'what': 60, 'who': 61, 'whom': 62, 'speaking': 63, 'speak': 64, 'the': 65, 'report': 66, 'unhappy': 67, 'some': 68, 'equipment': 69, 'needs': 70, 'fixed': 71, 'something': 72, 'not': 73, 'like': 74, 'now': 75, 'device': 76, 'that': 77, 'long': 78, 'will': 79, 'take': 80, 'here': 81, 'shipment': 82, 'drop': 83, 'dead': 84, 'die': 85, '1983': 86, '1234509873234323': 87, '0983834298342341': 88}\n","Size of vocab: 89\n"]}],"source":["size_of_vocabulary = len(tokenizer.word_index) + 1 #+1 for padding\n","print(tokenizer.word_index)\n","print(f'Size of vocab: {size_of_vocabulary}')"]},{"cell_type":"markdown","metadata":{"id":"wHf5PTZAKl-x"},"source":["# Build Model"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":490,"status":"ok","timestamp":1633681526110,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"UUMhzBOaKl-7","outputId":"9cbe2ead-3892-4e10-9856-0f29158b7a19"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 100, 300)          26700     \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 100, 128)          219648    \n","_________________________________________________________________\n","global_max_pooling1d_2 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 255,254\n","Trainable params: 255,254\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["from keras.models import *\n","from keras.layers import *\n","from keras.callbacks import *\n","\n","\n","model = Sequential()\n","#embedding layer\n","model.add(Embedding(size_of_vocabulary,300,input_length=100,trainable=True))\n","#lstm layer\n","model.add(LSTM(128,return_sequences=True,dropout=0.2))\n","#Global Maxpooling\n","model.add(GlobalMaxPooling1D())\n","#Dense Layer\n","model.add(Dense(64,activation='relu'))\n","model.add(Dense(len(list(le.classes_))-1,activation='sigmoid'))\n","#Add loss function, metrics, optimizer\n","model.compile(optimizer='adam',loss='categorical_crossentropy',\n","              metrics=['acc'])\n","#addingcallbacks\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n","mc = ModelCheckpoint(model_path_scratch, monitor='val_acc', mode='max', \n","                         save_best_only=True, verbose=1)\n","print(model.summary())\n"]},{"cell_type":"markdown","metadata":{"id":"a68HVsZmL615"},"source":["# Fit Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hMXzGUQEL2fm"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 0  0  0  0  0  0  0  0  0 27]\n"," [ 0  0  0  0  0  0 44  3 28  2]\n"," [ 0  0  0  0  0  0 15  2 46 14]\n"," [ 0  0  0  0  0  0  0 29  9  2]\n"," [ 0  0  0  0  0  0  6  9  2 30]\n"," [ 0  0  0  0  0  6  9  2 47 30]\n"," [ 0  0  0  0  0  0  6  9  2 50]\n"," [ 0  0  0  0  0  0  6 32  2 51]\n"," [ 0  0  0  0  0  0  6 10 31 18]\n"," [ 0  0  0  0  0  0  1 33  3 52]\n"," [ 0  0  0  0  0  0  0  0  0 53]\n"," [ 0  0  0  0  0  0  0  0  0 54]\n"," [ 0  0  0  0  0  0 55  3  2 34]\n"," [ 0  0  0  0  0  0  2  9 56 57]\n"," [ 0  0  0  0  0  0  0  0  0 58]\n"," [ 0  0  0  0  0  0  0  0 59  2]\n"," [ 0  0  0  0  0  0 60 10  7 35]\n"," [ 0  0  0  0  0  0  0 61  9  2]\n"," [ 0  0  0  0  0 36 62 19  1 63]\n"," [ 0  0  0  0 15  1 64  3  7 37]\n"," [ 0  0  0  0  0  0 38 14 65 37]\n"," [ 0  0  0  0  0  0  1  5  7 39]\n"," [ 0  0  0  0  0 20 14  3  7 39]\n"," [ 0  0  0  0  0  0  1 12  8 21]\n"," [ 0  0  0  0  1 12  3 20 68 40]\n"," [ 0  0  0  0  0  1  5  4 22 23]\n"," [ 0  0  0  0  0  0  4 24 10 25]\n"," [ 0  0  0  0  0  0  4 69 10 25]\n"," [ 0  0  0  0  0  0  4 24 70 71]\n"," [ 0  0  0  0  1 12  2  3 41 72]\n"," [ 0  0  0  0  1 32 73 74  7 11]\n"," [ 0  0  0  0  0  1  5  4 22 23]\n"," [ 0  0  0  0  0  1  5  8 21 75]\n"," [ 0  0  0  0  0 38 14  4 22 23]\n"," [ 0  0  0  0  0  0  4 76 10 25]\n"," [ 0  0  0  0  0  0  1  5  8 21]\n"," [ 0  0  0  0  1 12  3 16  8 13]\n"," [ 0  0  0  0  1  5  3 16  8 11]\n"," [ 0  1 33  8 11 77  1  5  3 16]\n"," [ 0  0  0  0  0  0 29 10  4 13]\n"," [ 0  6 78 79  4 13 80  3 20 81]\n"," [ 0  0  0  0  1  5  3 17  4 13]\n"," [ 0  0  0 15  2 40 14 17  4 13]\n"," [ 0  0  0  0  1  5  3 17  4 82]\n"," [ 0  0  0  0  0  0  0  0 83 84]\n"," [ 0  0  0  0  0  0  0  1 42  2]\n"," [ 0  0  0  0  0  0  0  0  0 87]\n"," [ 0  0  0  0  0  0  0  0  0 88]] [ 3  3  3  3  1  1  1  1  1  2  2  2  2  0  9  9  5  5  5  4  4  4  4  8\n","  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  6  6  6  6  6  7  7 10 10]\n","Epoch 1/10\n","WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 10).\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-20-538ec65f810b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     model.fit(np.array(x_train_fold),np.array(y_train_fold),batch_size=128,epochs=10,\n\u001b[1;32m      9\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 10\u001b[0;31m               verbose=1,callbacks=[es,mc])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-\u003e 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-\u003e 3460\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-\u003e 3382\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1666 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"]}],"source":["from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=5,shuffle=True, random_state=1)\n","lst_accu_stratified = []\n","for train_index, test_index in skf.split(X_all_seq, y_all):\n","    x_train_fold, x_test_fold = X_all_seq[train_index], X_all_seq[test_index]\n","    y_train_fold, y_test_fold = y_all[train_index], y_all[test_index]\n","    print(x_train_fold, y_train_fold)\n","    model.fit(np.array(x_train_fold),np.array(y_train_fold),batch_size=128,epochs=10,\n","              validation_data=(np.array(x_test_fold), np.array(y_test_fold)),\n","              verbose=1,callbacks=[es,mc])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OK_ku-ekGqG_"},"outputs":[],"source":["\n","# convert for k-fold sampling\n","X, y = X_all, y_all\n","\n","from sklearn.model_selection import cross_val_score\n","\n","model \n","# Tokenize the sentences\n","#tokenize\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","tokenizer = Tokenizer()\n","for train, val in skf.split(X, y):\n","    print(f'train  - {np.bincount(y[train])} | test - {np.bincount(y[test])}')\n","    # preparing vocabulary\n","    tokenizer.fit_on_texts(list(X[train]))\n","    # convert text into integer sequences\n","    x_tr_seq.extend(tokenizer.texts_to_sequences(X[train]))\n","    x_val_seq.extend(tokenizer.texts_to_sequences(X[val]))\n","    y_tr.extend(y[train])\n","    y_val.extend(y[val])\n","   \n","    #print(x_tr_seq[:5])\n","    #print(x_val_seq[:5])\n","    #print(x_tr_seq)\n","    # padding to prepare sequences of same length\n","    #all_sequences = pad_sequences(all_sequences, maxlen=100)\n","x_tr_seq = pad_sequences(x_tr_seq, maxlen=100)\n","x_val_seq = pad_sequences(x_val_seq, maxlen=100)\n","size_of_vocabulary = len(tokenizer.word_index) + 1\n","print(tokenizer.word_index)\n","print(f' Size of vocab: {size_of_vocabulary}')\n","    #print(all_patterns.shape)\n","    #print(label_encoded_Y.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":169,"status":"ok","timestamp":1633136630122,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"QhB-JGt4amCr","outputId":"a4da8ab4-1470-4433-9f8c-e2ca08ccd382"},"outputs":[{"name":"stdout","output_type":"stream","text":["122\n","122\n","61\n","61\n"]}],"source":["print(len(x_tr_seq))\n","print(len(y_tr))\n","print(len(x_val_seq))\n","print(len(y_val))"]},{"cell_type":"markdown","metadata":{"id":"PsQveR24bXX4"},"source":["# Load the Whole Embedding into Memory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120489,"status":"ok","timestamp":1633134977545,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"iH6l0PNmY_oN","outputId":"620b0d96-2ce3-46aa-cec7-6e3d74e36e84"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n","  \n"]},{"name":"stdout","output_type":"stream","text":["Found 2195884 word vectors.\n"]}],"source":["# load the whole embedding into memory\n","path_to_glove_file = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.840B.300d.txt'\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122,"status":"ok","timestamp":1633136846301,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"K3eGsdvFZUrl","outputId":"108aeda5-5c16-441c-ed4b-6248d626d3c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Converted 83 words (5 misses)\n","['to', 'is', \"how's\", '1234509873234323', '0983834298342341']\n"]}],"source":["# create a weight matrix for words in training docs\n","# create a weight matrix for words in training docs\n","embedding_matrix = np.zeros((size_of_vocabulary, 300))\n","hits = 0\n","misses = 0\n","missedWords = []\n","for word, i in tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None and embedding_vector.shape[0] != 0:       \n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","        missedWords.append(word)\n","print(f'Converted {hits} words ({misses} misses)')\n","print(missedWords)       \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1633136851410,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"1UofjkfFcjvM","outputId":"43e67982-db85-45bb-84b3-2fd8ae95834c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 100, 300)          26700     \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 100, 128)          219648    \n","_________________________________________________________________\n","global_max_pooling1d_4 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 254,669\n","Trainable params: 227,969\n","Non-trainable params: 26,700\n","_________________________________________________________________\n","None\n"]}],"source":["MODEL_NAME1 = 'best_model_scratch.h5'\n","MODEL_NAME2 = 'best_model_pretrained.h5'\n","model_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models'\n","\n","# build two different NLP models of the same architecture.  The first learns\n","# embeddings from scratch the second uses pretrained word embeddings\n","from keras.models import *\n","from keras.layers import *\n","from keras.callbacks import *\n","\n","#training = os.path.join(data_path, TRAIN_CSV)\n","#validation = os.path.join(data_path, VALID_CSV)\n","model_path_scratch = os.path.join(model_path, MODEL_NAME1)\n","model_path_pretrained = os.path.join(model_path, MODEL_NAME2)\n","\n","model = Sequential()\n","# Create model with 3 layers.  First layer 128 neurons, second layer 64 neurons\n","# and 3rd output layer contains number of neurons equal to number of intents to\n","# predict\n","# output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model.  Stochastic gradient descent with Nesterov accelerated\n","# gradient gives good\n","# results for this model\n","sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#embedding layer\n","model.add(Embedding(size_of_vocabulary,300,\n","                    weights=[embedding_matrix],\n","                    input_length=100,trainable=False))\n","\n","#lstm layer\n","model.add(LSTM(128,return_sequences=True,dropout=0.2))\n","\n","#Global Maxpooling\n","model.add(GlobalMaxPooling1D())\n","\n","model.add(Dense(64,activation='relu'))\n","model.add(Dense(len(,activation='softmax'))\n","\n","# add loss, metrics, optimizer\n","model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n","\n","# adding callbacks\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n","mc = ModelCheckpoint(model_path_pretrained, monitor='val_acc', mode='max', \n","                     save_best_only=True,verbose=1)\n","\n","#print summary of model\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8AhgAx6ygln0"},"outputs":[],"source":["y_tr = np.array(y_tr)\n","y_val = np.array(y_val)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1713,"status":"ok","timestamp":1633137091964,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"KLB8RMNQdv2n","outputId":"e60cc3ac-e300-4c08-9e5a-25151839f5c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1/1 [==============================] - 0s 378ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00001: val_acc did not improve from 0.09836\n","Epoch 2/10\n","1/1 [==============================] - 0s 329ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00002: val_acc did not improve from 0.09836\n","Epoch 3/10\n","1/1 [==============================] - 0s 353ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00003: val_acc did not improve from 0.09836\n","Epoch 4/10\n","1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00004: val_acc did not improve from 0.09836\n","Epoch 00004: early stopping\n"]}],"source":["history = model.fit(np.array(x_tr_seq),np.array(y_tr),batch_size=128,epochs=10,\n","                    validation_data=(np.array(x_val_seq),np.array(y_val)),\n","                    verbose=1,callbacks=[es,mc])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":153,"status":"ok","timestamp":1633133016751,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"MpI1AxDkT4Ey","outputId":"125a11d4-4772-4d64-dec1-acc803c5f7bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 1 1 1 1 1]\n"]}],"source":["\n","from sklearn.model_selection import StratifiedKFold, KFold\n","import numpy as np\n","X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n","print(X)\n","print(y)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1633132291327,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"},"user_tz":360},"id":"Lj3xZAWvQWPg","outputId":"5b970657-9b61-400d-9f39-58ff6930443d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[27], [43], [44, 3, 28, 2], [27, 45], [15, 2, 46, 14], [29, 9, 2], [6, 9, 2, 30], [6, 9, 2, 47, 30], [48, 31, 18, 49], [6, 9, 2, 50], [6, 32, 2, 51], [6, 10, 31, 18], [1, 33, 3, 52], [53], [54], [28, 2, 34], [55, 3, 2, 34], [2, 9, 56, 57], [58], [59, 2], [60, 10, 7, 35], [35], [61, 9, 2], [36, 62, 19, 1, 63], [15, 1, 64, 3, 7, 37], [38, 14, 65, 37], [1, 5, 7, 39], [1, 19, 18, 3, 66, 2], [20, 14, 3, 7, 39], [1, 19, 67, 36, 7, 11], [1, 12, 3, 16, 8, 11], [1, 12, 8, 21], [1, 12, 3, 20, 68, 40], [1, 5, 4, 22, 23], [4, 24, 10, 25], [4, 69, 10, 25], [4, 24, 70, 71], [1, 12, 2, 3, 41, 72], [1, 32, 73, 74, 7, 11], [1, 5, 4, 22, 23], [1, 5, 8, 21, 75], [38, 14, 4, 22, 23], [1, 42, 7, 11], [4, 76, 10, 25], [1, 12, 2, 3, 41, 4, 24], [1, 5, 8, 21], [1, 12, 3, 16, 8, 13], [1, 5, 3, 16, 8, 11], [1, 33, 8, 11, 77, 1, 5, 3, 16], [6, 15, 1, 17, 4, 13], [29, 10, 4, 13], [6, 78, 79, 4, 13, 80, 3, 20, 81], [1, 5, 3, 17, 4, 13], [15, 2, 40, 14, 17, 4, 13], [1, 5, 3, 17, 4, 82], [83, 84], [1, 42, 2], [1, 5, 2, 3, 85], [86, 26, 26, 26], [87], [88]]\n"," Size of vocab: 89\n"]}],"source":["#tokenize\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# Tokenize the sentences\n","tokenizer = Tokenizer()\n","# preparing vocabulary\n","tokenizer.fit_on_texts(list(all_patterns))\n","# convert text into integer sequences\n","all_sequences = tokenizer.texts_to_sequences(all_patterns)\n","print(all_sequences)\n","# padding to prepare sequences of same length\n","all_sequences = pad_sequences(all_sequences, maxlen=100)\n","size_of_vocabulary = len(tokenizer.word_index) + 1\n","print(f' Size of vocab: {size_of_vocabulary}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaa2dmVhK3tB"},"outputs":[],"source":["\n","\n","     for pattern in intent['patterns']:\n","          w = nltk.word_tokenize(pattern)\n","          words.extend(w)\n","\n","          documents.append((w, intent['tag']))\n","\n","          if intent['tag'] not in classes:\n","               classes.append(intent['tag'])\n","\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n","\n","classes = sorted(list(set(classes)))\n","\n","print(len(documents), 'documents')\n","print(len(classes), 'classes', classes)\n","print(len(words), 'unique lemmatized words', words)\n","\n","pickle.dump(words,open(os.path.join(intents_path, 'intents_words.pkl'),'wb'))\n","pickle.dump(classes,open(os.path.join(intents_path, 'intents_classes.pkl'),'wb'))\n","\n","# init training data\n","training = []\n","output_empty = [0] * len(classes)\n","for doc in documents:\n","    bag = []\n","    # english representation of words\n","    pattern_words = doc[0]\n","    # convert to lowercase and lemmatized versions\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","\n","    from keras.preprocessing.text import Tokenizer\n","    from keras.preprocessing.sequence import pad_sequences\n","\n","    #Tokenize the sentence \n","    for w in words:\n","         bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])\n","\n","random.shuffle(training)\n","training = np.array(training)\n","# create train and test lists.  X - patterns, y - intents\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print('Training data created')\n","\n","# Create model with 3 layers.  First layer 128 neurons, second layer 64 neurons\n","# and 3rd output layer contains number of neurons equal to number of intents to\n","# predict\n","# output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model.  Stochastic gradient descent with Nesterov accelerated\n","# gradient gives good\n","# results for this model\n","sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","# fitting and saving the model\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=1000, batch_size=5, verbose=1)\n","model.save(os.path.join(intents_path, 'intents_chatbot_model.h5'), hist)\n","\n","print('model created')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_h3u5oBVOWG"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_WHER_Pdr9B"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OYogec4BJBFT"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPdKVv3c8gUL6KHbcF8hCW5","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1wCci9CoVykMZnk1n1GzNTZjoWMx3Ijv4","name":"intents_train.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}