{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intents_train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1wCci9CoVykMZnk1n1GzNTZjoWMx3Ijv4","authorship_tag":"ABX9TyM/mEQb/3rks2m548Re/vc9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wFE1Byn9bRGk"},"source":["# Download Embeddings"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhdglgD9YENs","executionInfo":{"status":"ok","timestamp":1633134661605,"user_tz":360,"elapsed":503318,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"5d7d07ab-8cbe-4823-f4fb-d08ff2fde506"},"source":["import os\n","import tqdm\n","import requests\n","import zipfile\n","\n","URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n","\n","def fetch_data(url=URL, target_file='/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.zip', delete_zip=False):\n","    # if dataset exists exit\n","    if os.path.isfile(target_file):\n","        print('datasets already downloaded')\n","        return\n","\n","        #download (large) zip file\n","    #for large https request on stream mode to avoid out of memory issues\n","    #see : http://masnun.com/2016/09/18/python-using-the-requests-module-to-download-large-files-efficiently.html\n","    print(\"**************************\")\n","    print(\"  Downloading zip file\")\n","    print(\"  >_<  Please wait >_< \")\n","    print(\"**************************\")\n","    response = requests.get(url, stream=True)\n","    #read chunk by chunk\n","    handle = open(target_file, \"wb\")\n","    for chunk in tqdm.tqdm(response.iter_content(chunk_size=512)):\n","        if chunk:  \n","            handle.write(chunk)\n","    handle.close()  \n","    print(\"  Download completed ;) :\") \n","    #extract zip_file\n","    zf = zipfile.ZipFile(target_file)\n","    print(\"1. Extracting {} file\".format(target_file))\n","    zf.extractall(path='/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings')\n","    if delete_zip:\n","        print(\"2. Deleting {} file\".format(dataset_name+\".zip\"))\n","        os.remove(path=zip_file)\n","\n","fetch_data()"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["**************************\n","  Downloading zip file\n","  >_<  Please wait >_< \n","**************************\n"]},{"output_type":"stream","name":"stderr","text":["4251502it [06:51, 10337.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["  Download completed ;) :\n","1. Extracting /content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.zip file\n"]}]},{"cell_type":"markdown","metadata":{"id":"olOEGjoHK_oM"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BhS9gqsQQcHk","collapsed":true,"executionInfo":{"status":"ok","timestamp":1633148698162,"user_tz":360,"elapsed":283,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"c9a39f3f-f1f9-433f-a8d7-a3dd0159d7be"},"source":["import os\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import json\n","import pickle\n","\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers import SGD\n","import random\n","from sklearn import preprocessing\n"],"execution_count":143,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"CD7iDv_WLEm4"},"source":["# Set Variables"]},{"cell_type":"code","metadata":{"id":"IEoYFgQlK66T","executionInfo":{"status":"ok","timestamp":1633149481887,"user_tz":360,"elapsed":162,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["MODEL_NAME1 = 'best_model_scratch.h5'\n","MODEL_NAME2 = 'best_model_pretrained.h5'\n","model_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models'\n","\n","model_path_scratch = os.path.join(model_path, MODEL_NAME1)\n","model_path_pretrained = os.path.join(model_path, MODEL_NAME2)\n","\n","intents_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/data/intents'\n","\n","# inference model variables\n","inference_load_intents_from = os.path.join(intents_path, 'intents_job_intents.json')\n","\n","words = []\n","tags = []\n","documents = []\n","all_patterns = []\n","all_tags = []\n","label_encoded_Y = []\n","x_tr_seq = []\n","x_val_seq = []\n","y_tr = []\n","y_val = []\n","ignore_words = ['?', '!']"],"execution_count":163,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFxx-KBDCPWc"},"source":["# Load JSON"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"9JDcFJogdKsd","executionInfo":{"status":"ok","timestamp":1633149484984,"user_tz":360,"elapsed":161,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["data_file = open(inference_load_intents_from, encoding='cp1252').read()\n","intents = json.loads(data_file)"],"execution_count":164,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yOioSpstC1P7"},"source":["## Read in patterns and tags\n","\n","Patterns are the user input (i.e., 'Hi,' 'How are you?').\n","\n","Nothing is tokenized here."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8Yd42VXCtgO","executionInfo":{"status":"ok","timestamp":1633149487458,"user_tz":360,"elapsed":169,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"f13837f8-0145-49c9-dbe5-90da753bb48d"},"source":["# print classes\n","for intent in intents['intents']:\n","    all_patterns.extend(intent['patterns'])\n","    for pattern in intent['patterns']:\n","        all_tags.append(intent['tag'])\n","\n","print(all_tags)\n","print(all_patterns)"],"execution_count":165,"outputs":[{"output_type":"stream","name":"stdout","text":["['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'feeling', 'feeling', 'feeling', 'feeling', 'feeling', 'feeling', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'compliment', 'thanks', 'thanks', 'name', 'name', 'name', 'name', 'manager', 'manager', 'manager', 'manager', 'manager', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'return_product', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'package_tracking', 'profane', 'profane', 'profane', 'tracking', 'tracking', 'tracking']\n","['Hello', 'Hi', 'Good to see you.', 'Hello, there!', 'Can you hear me?', 'Where are you?', 'How are you today?', 'How are you doing today?', \"How's it going?'\", 'How are you feeling?', 'How do you feel?', 'How is it going?', 'I have to go.', 'Bye', 'Goodbye', 'See you later', 'Talk to you later', 'You are very helpful', 'Thanks', 'Thank you', 'What is your name?', 'Name?', 'Who are you?', 'With whom am I speaking?', 'Can I speak to your manager?', 'Give me the manager!', 'I want your supervisor.', 'I am going to report you.', 'Get me to your supervisor.', 'I am unhappy with your product.', 'I need to return a product.', 'I need a refund!', 'I need to get some help.', 'I want my money back.', 'My computer is broken.', 'My equipment is broken.', 'My computer needs fixed.', 'I need you to fix something', 'I do not like your product', 'I want my money back.', 'I want a refund, now!', 'Give me my money back!', 'I hate your product.', 'My device is broken.', 'I need you to fix my computer', 'I want a refund', 'I need to return a package.', 'I want to return a product.', 'I have a product that I want to return.', 'How can I track my package?', 'Where is my package?', 'How long will my package take to get here?', 'I want to track my package.', 'Can you help me track my package?', 'I want to track my shipment.', 'Drop dead.', 'I hate you.', 'I want you to die.', '1983-2343-2343-2343', '1234509873234323', '0983834298342341']\n"]}]},{"cell_type":"markdown","metadata":{"id":"a1RyLAppDkf7"},"source":["## Encode Tags\n"]},{"cell_type":"markdown","metadata":{"id":"XMGIsSR_D-Dm"},"source":["\n","### Fit"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ey2tdhgWDCyq","executionInfo":{"status":"ok","timestamp":1633149545828,"user_tz":360,"elapsed":133,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"3638b552-6b9d-4936-808d-e129e4512768"},"source":["# create label encoder\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","# fit on all tags from JSON file\n","le.fit(all_tags)\n","print(f'Number of classes: {len(list(le.classes_))}')"],"execution_count":168,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes: 11\n"]}]},{"cell_type":"markdown","metadata":{"id":"A38hiFKfEoh7"},"source":["### Transform"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nktR6B85FKbT","executionInfo":{"status":"ok","timestamp":1633149563804,"user_tz":360,"elapsed":139,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"f980bf25-6680-4a7a-f3fb-7b5ba30fac7c"},"source":["label_encoded_Y = le.transform(all_tags)\n","print(f'Label_encoded_Y: {label_encoded_Y}')\n","print(f'Label_encoded_Y bincount: {np.bincount(label_encoded_Y)}')"],"execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":["Label_encoded_Y: [ 3  3  3  3  3  3  1  1  1  1  1  1  2  2  2  2  2  0  9  9  5  5  5  5\n","  4  4  4  4  4  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n","  8  6  6  6  6  6  6  7  7  7 10 10 10]\n","Label_encoded_Y bincount: [ 1  6  5  6  5  4  6  3 20  2  3]\n"]}]},{"cell_type":"markdown","metadata":{"id":"bwhM8NHIGtFu"},"source":["## Create x_all, y_all"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48px4VM8DsZD","executionInfo":{"status":"ok","timestamp":1633149567532,"user_tz":360,"elapsed":167,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"05bebf4c-38c9-4d94-f860-4979b004b1ff"},"source":["X_all = np.asarray(all_patterns)\n","y_all = np.asarray(label_encoded_Y)\n","print(f'X all shape: {X_all.shape}')\n","print(f'Y all shape: {y_all.shape}')"],"execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["X all shape: (61,)\n","Y all shape: (61,)\n"]}]},{"cell_type":"markdown","metadata":{"id":"YWzLTI7BJEiK"},"source":["# Tokenize"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4leW3FIJHnj","executionInfo":{"status":"ok","timestamp":1633149570779,"user_tz":360,"elapsed":149,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"19d24d24-4eb6-4df6-a2fa-95892e9aeaa8"},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(list(X_all))\n","X_all_seq = tokenizer.texts_to_sequences(X_all)\n","print(X_all_seq)\n","print(type(X_all_seq))"],"execution_count":171,"outputs":[{"output_type":"stream","name":"stdout","text":["[[27], [43], [44, 3, 28, 2], [27, 45], [15, 2, 46, 14], [29, 9, 2], [6, 9, 2, 30], [6, 9, 2, 47, 30], [48, 31, 18, 49], [6, 9, 2, 50], [6, 32, 2, 51], [6, 10, 31, 18], [1, 33, 3, 52], [53], [54], [28, 2, 34], [55, 3, 2, 34], [2, 9, 56, 57], [58], [59, 2], [60, 10, 7, 35], [35], [61, 9, 2], [36, 62, 19, 1, 63], [15, 1, 64, 3, 7, 37], [38, 14, 65, 37], [1, 5, 7, 39], [1, 19, 18, 3, 66, 2], [20, 14, 3, 7, 39], [1, 19, 67, 36, 7, 11], [1, 12, 3, 16, 8, 11], [1, 12, 8, 21], [1, 12, 3, 20, 68, 40], [1, 5, 4, 22, 23], [4, 24, 10, 25], [4, 69, 10, 25], [4, 24, 70, 71], [1, 12, 2, 3, 41, 72], [1, 32, 73, 74, 7, 11], [1, 5, 4, 22, 23], [1, 5, 8, 21, 75], [38, 14, 4, 22, 23], [1, 42, 7, 11], [4, 76, 10, 25], [1, 12, 2, 3, 41, 4, 24], [1, 5, 8, 21], [1, 12, 3, 16, 8, 13], [1, 5, 3, 16, 8, 11], [1, 33, 8, 11, 77, 1, 5, 3, 16], [6, 15, 1, 17, 4, 13], [29, 10, 4, 13], [6, 78, 79, 4, 13, 80, 3, 20, 81], [1, 5, 3, 17, 4, 13], [15, 2, 40, 14, 17, 4, 13], [1, 5, 3, 17, 4, 82], [83, 84], [1, 42, 2], [1, 5, 2, 3, 85], [86, 26, 26, 26], [87], [88]]\n","<class 'list'>\n"]}]},{"cell_type":"markdown","metadata":{"id":"uVmE5G9RJyCp"},"source":["### Pad"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1tA5wqBJ0HS","executionInfo":{"status":"ok","timestamp":1633151169029,"user_tz":360,"elapsed":147,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"1fb06a51-78b7-48bf-aa69-b0e676b900ef"},"source":["# padding to prepare sequences of same length\n","X_all_seq = pad_sequences(X_all_seq, maxlen=10)\n","print(X_all_seq)\n","#type is now a numpy.ndarray\n","print(type(X_all_seq))\n","print(f'Shape (X_all): {X_all_seq.shape}')"],"execution_count":205,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0  0  0  0  0  0  0 27]\n"," [ 0  0  0  0  0  0  0  0  0 43]\n"," [ 0  0  0  0  0  0 44  3 28  2]\n"," [ 0  0  0  0  0  0  0  0 27 45]\n"," [ 0  0  0  0  0  0 15  2 46 14]\n"," [ 0  0  0  0  0  0  0 29  9  2]\n"," [ 0  0  0  0  0  0  6  9  2 30]\n"," [ 0  0  0  0  0  6  9  2 47 30]\n"," [ 0  0  0  0  0  0 48 31 18 49]\n"," [ 0  0  0  0  0  0  6  9  2 50]\n"," [ 0  0  0  0  0  0  6 32  2 51]\n"," [ 0  0  0  0  0  0  6 10 31 18]\n"," [ 0  0  0  0  0  0  1 33  3 52]\n"," [ 0  0  0  0  0  0  0  0  0 53]\n"," [ 0  0  0  0  0  0  0  0  0 54]\n"," [ 0  0  0  0  0  0  0 28  2 34]\n"," [ 0  0  0  0  0  0 55  3  2 34]\n"," [ 0  0  0  0  0  0  2  9 56 57]\n"," [ 0  0  0  0  0  0  0  0  0 58]\n"," [ 0  0  0  0  0  0  0  0 59  2]\n"," [ 0  0  0  0  0  0 60 10  7 35]\n"," [ 0  0  0  0  0  0  0  0  0 35]\n"," [ 0  0  0  0  0  0  0 61  9  2]\n"," [ 0  0  0  0  0 36 62 19  1 63]\n"," [ 0  0  0  0 15  1 64  3  7 37]\n"," [ 0  0  0  0  0  0 38 14 65 37]\n"," [ 0  0  0  0  0  0  1  5  7 39]\n"," [ 0  0  0  0  1 19 18  3 66  2]\n"," [ 0  0  0  0  0 20 14  3  7 39]\n"," [ 0  0  0  0  1 19 67 36  7 11]\n"," [ 0  0  0  0  1 12  3 16  8 11]\n"," [ 0  0  0  0  0  0  1 12  8 21]\n"," [ 0  0  0  0  1 12  3 20 68 40]\n"," [ 0  0  0  0  0  1  5  4 22 23]\n"," [ 0  0  0  0  0  0  4 24 10 25]\n"," [ 0  0  0  0  0  0  4 69 10 25]\n"," [ 0  0  0  0  0  0  4 24 70 71]\n"," [ 0  0  0  0  1 12  2  3 41 72]\n"," [ 0  0  0  0  1 32 73 74  7 11]\n"," [ 0  0  0  0  0  1  5  4 22 23]\n"," [ 0  0  0  0  0  1  5  8 21 75]\n"," [ 0  0  0  0  0 38 14  4 22 23]\n"," [ 0  0  0  0  0  0  1 42  7 11]\n"," [ 0  0  0  0  0  0  4 76 10 25]\n"," [ 0  0  0  1 12  2  3 41  4 24]\n"," [ 0  0  0  0  0  0  1  5  8 21]\n"," [ 0  0  0  0  1 12  3 16  8 13]\n"," [ 0  0  0  0  1  5  3 16  8 11]\n"," [ 0  0  0  8 11 77  1  5  3 16]\n"," [ 0  0  0  0  6 15  1 17  4 13]\n"," [ 0  0  0  0  0  0 29 10  4 13]\n"," [ 0  0  0 79  4 13 80  3 20 81]\n"," [ 0  0  0  0  1  5  3 17  4 13]\n"," [ 0  0  0 15  2 40 14 17  4 13]\n"," [ 0  0  0  0  1  5  3 17  4 82]\n"," [ 0  0  0  0  0  0  0  0 83 84]\n"," [ 0  0  0  0  0  0  0  1 42  2]\n"," [ 0  0  0  0  0  1  5  2  3 85]\n"," [ 0  0  0  0  0  0 86 26 26 26]\n"," [ 0  0  0  0  0  0  0  0  0 87]\n"," [ 0  0  0  0  0  0  0  0  0 88]]\n","<class 'numpy.ndarray'>\n","Shape (X_all): (61, 10)\n"]}]},{"cell_type":"markdown","metadata":{"id":"J8ateuv7KQ7T"},"source":["# Vocab Size"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrgIj7a4KQ7T","executionInfo":{"status":"ok","timestamp":1633151172209,"user_tz":360,"elapsed":160,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"0d43050f-fc05-4a8e-dc5b-99232b46aa42"},"source":["size_of_vocabulary = len(tokenizer.word_index) + 1 #+1 for padding\n","print(tokenizer.word_index)\n","print(f'Size of vocab: {size_of_vocabulary}')"],"execution_count":206,"outputs":[{"output_type":"stream","name":"stdout","text":["{'i': 1, 'you': 2, 'to': 3, 'my': 4, 'want': 5, 'how': 6, 'your': 7, 'a': 8, 'are': 9, 'is': 10, 'product': 11, 'need': 12, 'package': 13, 'me': 14, 'can': 15, 'return': 16, 'track': 17, 'going': 18, 'am': 19, 'get': 20, 'refund': 21, 'money': 22, 'back': 23, 'computer': 24, 'broken': 25, '2343': 26, 'hello': 27, 'see': 28, 'where': 29, 'today': 30, 'it': 31, 'do': 32, 'have': 33, 'later': 34, 'name': 35, 'with': 36, 'manager': 37, 'give': 38, 'supervisor': 39, 'help': 40, 'fix': 41, 'hate': 42, 'hi': 43, 'good': 44, 'there': 45, 'hear': 46, 'doing': 47, \"how's\": 48, \"'\": 49, 'feeling': 50, 'feel': 51, 'go': 52, 'bye': 53, 'goodbye': 54, 'talk': 55, 'very': 56, 'helpful': 57, 'thanks': 58, 'thank': 59, 'what': 60, 'who': 61, 'whom': 62, 'speaking': 63, 'speak': 64, 'the': 65, 'report': 66, 'unhappy': 67, 'some': 68, 'equipment': 69, 'needs': 70, 'fixed': 71, 'something': 72, 'not': 73, 'like': 74, 'now': 75, 'device': 76, 'that': 77, 'long': 78, 'will': 79, 'take': 80, 'here': 81, 'shipment': 82, 'drop': 83, 'dead': 84, 'die': 85, '1983': 86, '1234509873234323': 87, '0983834298342341': 88}\n","Size of vocab: 89\n"]}]},{"cell_type":"markdown","metadata":{"id":"wHf5PTZAKl-x"},"source":["# Build Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"UUMhzBOaKl-7","executionInfo":{"status":"ok","timestamp":1633152435285,"user_tz":360,"elapsed":528,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"40e1968c-d0a4-47c9-fe75-be8dd2d51fee"},"source":["from keras.models import *\n","from keras.layers import *\n","from keras.callbacks import *\n","\n","\n","model = Sequential()\n","#embedding layer\n","model.add(Embedding(size_of_vocabulary,300,input_length=100,trainable=True))\n","#lstm layer\n","model.add(LSTM(128,return_sequences=True,dropout=0.2))\n","#Global Maxpooling\n","model.add(GlobalMaxPooling1D())\n","#Dense Layer\n","model.add(Dense(64,activation='relu'))\n","model.add(Dense(len(list(le.classes_)),activation='softmax'))\n","#Add loss function, metrics, optimizer\n","model.compile(optimizer='adam',loss='categorical_crossentropy',\n","              metrics=['acc'])\n","#addingcallbacks\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n","mc = ModelCheckpoint(model_path_scratch, monitor='val_acc', mode='max', \n","                         save_best_only=True, verbose=1)\n","print(model.summary())\n"],"execution_count":212,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_37\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_36 (Embedding)     (None, 100, 300)          26700     \n","_________________________________________________________________\n","lstm_36 (LSTM)               (None, 100, 128)          219648    \n","_________________________________________________________________\n","global_max_pooling1d_36 (Glo (None, 128)               0         \n","_________________________________________________________________\n","dense_72 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dense_73 (Dense)             (None, 11)                715       \n","=================================================================\n","Total params: 255,319\n","Trainable params: 255,319\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"a68HVsZmL615"},"source":["# Fit Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hMXzGUQEL2fm","executionInfo":{"status":"error","timestamp":1633152478216,"user_tz":360,"elapsed":501,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"e174a308-d963-4756-caf5-126e14192a9c"},"source":["from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=5,shuffle=True, random_state=1)\n","lst_accu_stratified = []\n","for train_index, test_index in skf.split(X_all_seq, y_all):\n","    x_train_fold, x_test_fold = X_all_seq[train_index], X_all_seq[test_index]\n","    y_train_fold, y_test_fold = y_all[train_index], y_all[test_index]\n","    print(x_train_fold, y_train_fold)\n","    model.fit(x_train_fold,y_train_fold,batch_size=128,epochs=10,\n","              validation_data=(x_test_fold, y_test_fold),\n","              verbose=1)\n"],"execution_count":214,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0  0  0  0  0  0  0 27]\n"," [ 0  0  0  0  0  0 44  3 28  2]\n"," [ 0  0  0  0  0  0 15  2 46 14]\n"," [ 0  0  0  0  0  0  0 29  9  2]\n"," [ 0  0  0  0  0  0  6  9  2 30]\n"," [ 0  0  0  0  0  6  9  2 47 30]\n"," [ 0  0  0  0  0  0  6  9  2 50]\n"," [ 0  0  0  0  0  0  6 32  2 51]\n"," [ 0  0  0  0  0  0  6 10 31 18]\n"," [ 0  0  0  0  0  0  1 33  3 52]\n"," [ 0  0  0  0  0  0  0  0  0 53]\n"," [ 0  0  0  0  0  0  0  0  0 54]\n"," [ 0  0  0  0  0  0 55  3  2 34]\n"," [ 0  0  0  0  0  0  2  9 56 57]\n"," [ 0  0  0  0  0  0  0  0  0 58]\n"," [ 0  0  0  0  0  0  0  0 59  2]\n"," [ 0  0  0  0  0  0 60 10  7 35]\n"," [ 0  0  0  0  0  0  0 61  9  2]\n"," [ 0  0  0  0  0 36 62 19  1 63]\n"," [ 0  0  0  0 15  1 64  3  7 37]\n"," [ 0  0  0  0  0  0 38 14 65 37]\n"," [ 0  0  0  0  0  0  1  5  7 39]\n"," [ 0  0  0  0  0 20 14  3  7 39]\n"," [ 0  0  0  0  0  0  1 12  8 21]\n"," [ 0  0  0  0  1 12  3 20 68 40]\n"," [ 0  0  0  0  0  1  5  4 22 23]\n"," [ 0  0  0  0  0  0  4 24 10 25]\n"," [ 0  0  0  0  0  0  4 69 10 25]\n"," [ 0  0  0  0  0  0  4 24 70 71]\n"," [ 0  0  0  0  1 12  2  3 41 72]\n"," [ 0  0  0  0  1 32 73 74  7 11]\n"," [ 0  0  0  0  0  1  5  4 22 23]\n"," [ 0  0  0  0  0  1  5  8 21 75]\n"," [ 0  0  0  0  0 38 14  4 22 23]\n"," [ 0  0  0  0  0  0  4 76 10 25]\n"," [ 0  0  0  0  0  0  1  5  8 21]\n"," [ 0  0  0  0  1 12  3 16  8 13]\n"," [ 0  0  0  0  1  5  3 16  8 11]\n"," [ 0  0  0  8 11 77  1  5  3 16]\n"," [ 0  0  0  0  0  0 29 10  4 13]\n"," [ 0  0  0 79  4 13 80  3 20 81]\n"," [ 0  0  0  0  1  5  3 17  4 13]\n"," [ 0  0  0 15  2 40 14 17  4 13]\n"," [ 0  0  0  0  1  5  3 17  4 82]\n"," [ 0  0  0  0  0  0  0  0 83 84]\n"," [ 0  0  0  0  0  0  0  1 42  2]\n"," [ 0  0  0  0  0  0  0  0  0 87]\n"," [ 0  0  0  0  0  0  0  0  0 88]] [ 3  3  3  3  1  1  1  1  1  2  2  2  2  0  9  9  5  5  5  4  4  4  4  8\n","  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  6  6  6  6  6  7  7 10 10]\n","Epoch 1/10\n","WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='embedding_36_input'), name='embedding_36_input', description=\"created by layer 'embedding_36_input'\"), but it was called on an input with incompatible shape (None, 10).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  % (min_groups, self.n_splits)), UserWarning)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-214-fec9c375d6c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     model.fit(x_train_fold,y_train_fold,batch_size=128,epochs=10,\n\u001b[1;32m      9\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:789 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/losses.py:1666 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/backend.py:4839 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 11) are incompatible\n"]}]},{"cell_type":"code","metadata":{"id":"OK_ku-ekGqG_"},"source":["\n","# convert for k-fold sampling\n","X, y = X_all, y_all\n","\n","from sklearn.model_selection import cross_val_score\n","\n","model \n","# Tokenize the sentences\n","#tokenize\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","tokenizer = Tokenizer()\n","for train, val in skf.split(X, y):\n","    print(f'train  - {np.bincount(y[train])} | test - {np.bincount(y[test])}')\n","    # preparing vocabulary\n","    tokenizer.fit_on_texts(list(X[train]))\n","    # convert text into integer sequences\n","    x_tr_seq.extend(tokenizer.texts_to_sequences(X[train]))\n","    x_val_seq.extend(tokenizer.texts_to_sequences(X[val]))\n","    y_tr.extend(y[train])\n","    y_val.extend(y[val])\n","   \n","    #print(x_tr_seq[:5])\n","    #print(x_val_seq[:5])\n","    #print(x_tr_seq)\n","    # padding to prepare sequences of same length\n","    #all_sequences = pad_sequences(all_sequences, maxlen=100)\n","x_tr_seq = pad_sequences(x_tr_seq, maxlen=100)\n","x_val_seq = pad_sequences(x_val_seq, maxlen=100)\n","size_of_vocabulary = len(tokenizer.word_index) + 1\n","print(tokenizer.word_index)\n","print(f' Size of vocab: {size_of_vocabulary}')\n","    #print(all_patterns.shape)\n","    #print(label_encoded_Y.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"QhB-JGt4amCr","executionInfo":{"status":"ok","timestamp":1633136630122,"user_tz":360,"elapsed":169,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"a4da8ab4-1470-4433-9f8c-e2ca08ccd382"},"source":["print(len(x_tr_seq))\n","print(len(y_tr))\n","print(len(x_val_seq))\n","print(len(y_val))"],"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["122\n","122\n","61\n","61\n"]}]},{"cell_type":"markdown","metadata":{"id":"PsQveR24bXX4"},"source":["# Load the Whole Embedding into Memory"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iH6l0PNmY_oN","executionInfo":{"status":"ok","timestamp":1633134977545,"user_tz":360,"elapsed":120489,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"620b0d96-2ce3-46aa-cec7-6e3d74e36e84"},"source":["# load the whole embedding into memory\n","path_to_glove_file = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/embeddings/glove.840B.300d.txt'\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Found 2195884 word vectors.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3eGsdvFZUrl","executionInfo":{"status":"ok","timestamp":1633136846301,"user_tz":360,"elapsed":122,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"108aeda5-5c16-441c-ed4b-6248d626d3c2"},"source":["# create a weight matrix for words in training docs\n","# create a weight matrix for words in training docs\n","embedding_matrix = np.zeros((size_of_vocabulary, 300))\n","hits = 0\n","misses = 0\n","missedWords = []\n","for word, i in tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None and embedding_vector.shape[0] != 0:       \n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","        missedWords.append(word)\n","print(f'Converted {hits} words ({misses} misses)')\n","print(missedWords)       \n"],"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted 83 words (5 misses)\n","['to', 'is', \"how's\", '1234509873234323', '0983834298342341']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UofjkfFcjvM","executionInfo":{"status":"ok","timestamp":1633136851410,"user_tz":360,"elapsed":467,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"43e67982-db85-45bb-84b3-2fd8ae95834c"},"source":["MODEL_NAME1 = 'best_model_scratch.h5'\n","MODEL_NAME2 = 'best_model_pretrained.h5'\n","model_path = '/content/drive/MyDrive/Colab Notebooks/chatbot-flask-simple/models'\n","\n","# build two different NLP models of the same architecture.  The first learns\n","# embeddings from scratch the second uses pretrained word embeddings\n","from keras.models import *\n","from keras.layers import *\n","from keras.callbacks import *\n","\n","#training = os.path.join(data_path, TRAIN_CSV)\n","#validation = os.path.join(data_path, VALID_CSV)\n","model_path_scratch = os.path.join(model_path, MODEL_NAME1)\n","model_path_pretrained = os.path.join(model_path, MODEL_NAME2)\n","\n","model = Sequential()\n","# Create model with 3 layers.  First layer 128 neurons, second layer 64 neurons\n","# and 3rd output layer contains number of neurons equal to number of intents to\n","# predict\n","# output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model.  Stochastic gradient descent with Nesterov accelerated\n","# gradient gives good\n","# results for this model\n","sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#embedding layer\n","model.add(Embedding(size_of_vocabulary,300,\n","                    weights=[embedding_matrix],\n","                    input_length=100,trainable=False))\n","\n","#lstm layer\n","model.add(LSTM(128,return_sequences=True,dropout=0.2))\n","\n","#Global Maxpooling\n","model.add(GlobalMaxPooling1D())\n","\n","model.add(Dense(64,activation='relu'))\n","model.add(Dense(len(,activation='softmax'))\n","\n","# add loss, metrics, optimizer\n","model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n","\n","# adding callbacks\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\n","mc = ModelCheckpoint(model_path_pretrained, monitor='val_acc', mode='max', \n","                     save_best_only=True,verbose=1)\n","\n","#print summary of model\n","print(model.summary())"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 100, 300)          26700     \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 100, 128)          219648    \n","_________________________________________________________________\n","global_max_pooling1d_4 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 254,669\n","Trainable params: 227,969\n","Non-trainable params: 26,700\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","metadata":{"id":"8AhgAx6ygln0","executionInfo":{"status":"ok","timestamp":1633137086874,"user_tz":360,"elapsed":130,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}}},"source":["y_tr = np.array(y_tr)\n","y_val = np.array(y_val)\n"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLB8RMNQdv2n","executionInfo":{"status":"ok","timestamp":1633137091964,"user_tz":360,"elapsed":1713,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"e60cc3ac-e300-4c08-9e5a-25151839f5c9"},"source":["history = model.fit(np.array(x_tr_seq),np.array(y_tr),batch_size=128,epochs=10,\n","                    validation_data=(np.array(x_val_seq),np.array(y_val)),\n","                    verbose=1,callbacks=[es,mc])\n","\n","\n"],"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1/1 [==============================] - 0s 378ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00001: val_acc did not improve from 0.09836\n","Epoch 2/10\n","1/1 [==============================] - 0s 329ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00002: val_acc did not improve from 0.09836\n","Epoch 3/10\n","1/1 [==============================] - 0s 353ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00003: val_acc did not improve from 0.09836\n","Epoch 4/10\n","1/1 [==============================] - 0s 351ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0984\n","\n","Epoch 00004: val_acc did not improve from 0.09836\n","Epoch 00004: early stopping\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MpI1AxDkT4Ey","executionInfo":{"status":"ok","timestamp":1633133016751,"user_tz":360,"elapsed":153,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"125a11d4-4772-4d64-dec1-acc803c5f7bf"},"source":["\n","from sklearn.model_selection import StratifiedKFold, KFold\n","import numpy as np\n","X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n","print(X)\n","print(y)\n"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 1 1 1 1 1]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj3xZAWvQWPg","executionInfo":{"status":"ok","timestamp":1633132291327,"user_tz":360,"elapsed":167,"user":{"displayName":"Scott Miner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxCt3KNHFc4ZlPw4tBG4aCXpKie347LZ9L1JAVuA=s64","userId":"08363991975257577328"}},"outputId":"5b970657-9b61-400d-9f39-58ff6930443d"},"source":["#tokenize\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# Tokenize the sentences\n","tokenizer = Tokenizer()\n","# preparing vocabulary\n","tokenizer.fit_on_texts(list(all_patterns))\n","# convert text into integer sequences\n","all_sequences = tokenizer.texts_to_sequences(all_patterns)\n","print(all_sequences)\n","# padding to prepare sequences of same length\n","all_sequences = pad_sequences(all_sequences, maxlen=100)\n","size_of_vocabulary = len(tokenizer.word_index) + 1\n","print(f' Size of vocab: {size_of_vocabulary}')"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[[27], [43], [44, 3, 28, 2], [27, 45], [15, 2, 46, 14], [29, 9, 2], [6, 9, 2, 30], [6, 9, 2, 47, 30], [48, 31, 18, 49], [6, 9, 2, 50], [6, 32, 2, 51], [6, 10, 31, 18], [1, 33, 3, 52], [53], [54], [28, 2, 34], [55, 3, 2, 34], [2, 9, 56, 57], [58], [59, 2], [60, 10, 7, 35], [35], [61, 9, 2], [36, 62, 19, 1, 63], [15, 1, 64, 3, 7, 37], [38, 14, 65, 37], [1, 5, 7, 39], [1, 19, 18, 3, 66, 2], [20, 14, 3, 7, 39], [1, 19, 67, 36, 7, 11], [1, 12, 3, 16, 8, 11], [1, 12, 8, 21], [1, 12, 3, 20, 68, 40], [1, 5, 4, 22, 23], [4, 24, 10, 25], [4, 69, 10, 25], [4, 24, 70, 71], [1, 12, 2, 3, 41, 72], [1, 32, 73, 74, 7, 11], [1, 5, 4, 22, 23], [1, 5, 8, 21, 75], [38, 14, 4, 22, 23], [1, 42, 7, 11], [4, 76, 10, 25], [1, 12, 2, 3, 41, 4, 24], [1, 5, 8, 21], [1, 12, 3, 16, 8, 13], [1, 5, 3, 16, 8, 11], [1, 33, 8, 11, 77, 1, 5, 3, 16], [6, 15, 1, 17, 4, 13], [29, 10, 4, 13], [6, 78, 79, 4, 13, 80, 3, 20, 81], [1, 5, 3, 17, 4, 13], [15, 2, 40, 14, 17, 4, 13], [1, 5, 3, 17, 4, 82], [83, 84], [1, 42, 2], [1, 5, 2, 3, 85], [86, 26, 26, 26], [87], [88]]\n"," Size of vocab: 89\n"]}]},{"cell_type":"code","metadata":{"id":"jaa2dmVhK3tB"},"source":["\n","\n","     for pattern in intent['patterns']:\n","          w = nltk.word_tokenize(pattern)\n","          words.extend(w)\n","\n","          documents.append((w, intent['tag']))\n","\n","          if intent['tag'] not in classes:\n","               classes.append(intent['tag'])\n","\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n","\n","classes = sorted(list(set(classes)))\n","\n","print(len(documents), 'documents')\n","print(len(classes), 'classes', classes)\n","print(len(words), 'unique lemmatized words', words)\n","\n","pickle.dump(words,open(os.path.join(intents_path, 'intents_words.pkl'),'wb'))\n","pickle.dump(classes,open(os.path.join(intents_path, 'intents_classes.pkl'),'wb'))\n","\n","# init training data\n","training = []\n","output_empty = [0] * len(classes)\n","for doc in documents:\n","    bag = []\n","    # english representation of words\n","    pattern_words = doc[0]\n","    # convert to lowercase and lemmatized versions\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","\n","    from keras.preprocessing.text import Tokenizer\n","    from keras.preprocessing.sequence import pad_sequences\n","\n","    #Tokenize the sentence \n","    for w in words:\n","         bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])\n","\n","random.shuffle(training)\n","training = np.array(training)\n","# create train and test lists.  X - patterns, y - intents\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print('Training data created')\n","\n","# Create model with 3 layers.  First layer 128 neurons, second layer 64 neurons\n","# and 3rd output layer contains number of neurons equal to number of intents to\n","# predict\n","# output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model.  Stochastic gradient descent with Nesterov accelerated\n","# gradient gives good\n","# results for this model\n","sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","# fitting and saving the model\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=1000, batch_size=5, verbose=1)\n","model.save(os.path.join(intents_path, 'intents_chatbot_model.h5'), hist)\n","\n","print('model created')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_h3u5oBVOWG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_WHER_Pdr9B"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYogec4BJBFT"},"source":[""],"execution_count":null,"outputs":[]}]}